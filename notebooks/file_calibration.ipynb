{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "504e14fa",
   "metadata": {},
   "source": [
    "# Single File Calibration\n",
    "\n",
    "**by Josh Dillon, Aaron Parsons, Tyler Cox, and Zachary Martinot**, last updated March 14, 2023\n",
    "\n",
    "This notebook is designed to infer as much information about the array from a single file, including pushing the calibration and RFI mitigation as far as possible. Calibration includes redundant-baseline calibration, RFI-based calibration of delay slopes, model-based calibration of overall amplitudes, and a full per-frequency phase gradient absolute calibration if abscal model files are available.\n",
    "\n",
    "Here's a set of links to skip to particular figures and tables:\n",
    "# [• Figure 1: RFI Flagging](#Figure-1:-RFI-Flagging)\n",
    "# [• Figure 2: Plot of autocorrelations with classifications](#Figure-2:-Plot-of-autocorrelations-with-classifications)\n",
    "# [• Figure 3: Summary of antenna classifications prior to calibration](#Figure-3:-Summary-of-antenna-classifications-prior-to-calibration)\n",
    "# [• Figure 4: Redundant calibration of a single baseline group](#Figure-4:-Redundant-calibration-of-a-single-baseline-group)\n",
    "# [• Figure 5: Absolute calibration of redcal degeneracies](#Figure-5:-Absolute-calibration-of-redcal-degeneracies)\n",
    "# [• Figure 6: chi^2 per antenna across the array](#Figure-6:-chi^2-per-antenna-across-the-array)\n",
    "# [• Figure 7: Summary of antenna classifications after redundant calibration](#Figure-7:-Summary-of-antenna-classifications-after-redundant-calibration)\n",
    "# [• Table 1: Complete summary of per antenna classifications](#Table-1:-Complete-summary-of-per-antenna-classifications)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e92f02b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "tstart = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "668f7418",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['HDF5_USE_FILE_LOCKING'] = 'FALSE'\n",
    "import h5py\n",
    "import hdf5plugin  # REQUIRED to have the compression plugins available\n",
    "import numpy as np\n",
    "from scipy import constants, interpolate\n",
    "import copy\n",
    "import glob\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_rows', 1000)\n",
    "from uvtools.plot import plot_antpos, plot_antclass\n",
    "from hera_qm import ant_metrics, ant_class, xrfi\n",
    "from hera_cal import io, utils, redcal, apply_cal, datacontainer, abscal\n",
    "from hera_notebook_templates.data import DATA_PATH as HNBT_DATA\n",
    "from IPython.display import display, HTML\n",
    "import linsolve\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))\n",
    "_ = np.seterr(all='ignore')  # get rid of red warnings\n",
    "%config InlineBackend.figure_format = 'retina'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef7c7cbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this enables better memory management on linux\n",
    "import ctypes\n",
    "def malloc_trim():\n",
    "    try:\n",
    "        ctypes.CDLL('libc.so.6').malloc_trim(0) \n",
    "    except OSError:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab0f8167",
   "metadata": {},
   "source": [
    "## Parse inputs and outputs\n",
    "\n",
    "To use this notebook interactively, you will have to provide a sum filename path if none exists as an environment variable. All other parameters have reasonable default values.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b88cc02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# figure out whether to save results\n",
    "SAVE_RESULTS = os.environ.get(\"SAVE_RESULTS\", \"TRUE\").upper() == \"TRUE\"\n",
    "\n",
    "# get infile names\n",
    "SUM_FILE = os.environ.get(\"SUM_FILE\", None)\n",
    "\n",
    "# SUM_FILE = '/mnt/sn1/2459797/zen.2459797.30001.sum.uvh5'  # If sum_file is not defined in the environment variables, define it here.\n",
    "DIFF_FILE = SUM_FILE.replace('sum', 'diff')\n",
    "\n",
    "# get outfilenames\n",
    "AM_FILE = (SUM_FILE.replace('.uvh5', '.ant_metrics.hdf5') if SAVE_RESULTS else None)\n",
    "ANTCLASS_FILE = (SUM_FILE.replace('.uvh5', '.ant_class.csv') if SAVE_RESULTS else None)\n",
    "OMNICAL_FILE = (SUM_FILE.replace('.uvh5', '.omni.calfits') if SAVE_RESULTS else None)\n",
    "OMNIVIS_FILE = (SUM_FILE.replace('.uvh5', '.omni_vis.uvh5') if SAVE_RESULTS else None)\n",
    "\n",
    "for fname in ['SUM_FILE', 'DIFF_FILE', 'AM_FILE', 'ANTCLASS_FILE', 'OMNICAL_FILE', 'OMNIVIS_FILE']:\n",
    "    print(f\"{fname} = '{eval(fname)}'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8105807c",
   "metadata": {},
   "source": [
    "### Parse settings\n",
    "Load settings relating to the operation of the notebook, then print what was loaded (or default)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e65c0bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# parse plotting settings\n",
    "PLOT = os.environ.get(\"PLOT\", \"TRUE\").upper() == \"TRUE\"\n",
    "if PLOT:\n",
    "    %matplotlib inline\n",
    "\n",
    "# parse omnical settings\n",
    "OC_MAX_DIMS = int(os.environ.get(\"OC_MAX_DIMS\", 4))\n",
    "OC_MIN_DIM_SIZE = int(os.environ.get(\"OC_MIN_DIM_SIZE\", 8))\n",
    "OC_SKIP_OUTRIGGERS = os.environ.get(\"OC_SKIP_OUTRIGGERS\", \"TRUE\").upper() == \"TRUE\"\n",
    "OC_MIN_BL_LEN = float(os.environ.get(\"OC_MIN_BL_LEN\", 1))\n",
    "OC_MAX_BL_LEN = float(os.environ.get(\"OC_MAX_BL_LEN\", 1e100))\n",
    "OC_MAXITER = int(os.environ.get(\"OC_MAXITER\", 50))\n",
    "OC_MAX_RERUN = int(os.environ.get(\"OC_MAX_RERUN\", 4))\n",
    "OC_USE_GPU = os.environ.get(\"SAVE_RESULTS\", \"FALSE\").upper() == \"TRUE\"\n",
    "\n",
    "# parse RFI settings\n",
    "RFI_DPSS_HALFWIDTH = float(os.environ.get(\"RFI_DPSS_HALFWIDTH\", 300e-9))\n",
    "RFI_NSIG = float(os.environ.get(\"RFI_NSIG\", 6))\n",
    "\n",
    "# parse abscal settings\n",
    "ABSCAL_MODEL_FILES_GLOB = os.environ.get(\"ABSCAL_MODEL_FILES_GLOB\", None)\n",
    "ABSCAL_MIN_BL_LEN = float(os.environ.get(\"ABSCAL_MIN_BL_LEN\", 1.0))\n",
    "ABSCAL_MAX_BL_LEN = float(os.environ.get(\"ABSCAL_MAX_BL_LEN\", 140.0))\n",
    "\n",
    "# print settings\n",
    "for setting in ['PLOT', 'SAVE_RESULTS', 'OC_MAX_DIMS', 'OC_MIN_DIM_SIZE', 'OC_SKIP_OUTRIGGERS', \n",
    "                'OC_MIN_BL_LEN', 'OC_MAX_BL_LEN', 'OC_MAXITER', 'OC_MAX_RERUN',\n",
    "                'OC_USE_GPU', 'RFI_DPSS_HALFWIDTH', 'RFI_NSIG', 'ABSCAL_MODEL_FILES_GLOB', \n",
    "                'ABSCAL_MIN_BL_LEN', 'ABSCAL_MAX_BL_LEN']:\n",
    "    print(f'{setting} = {eval(setting)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5596c041",
   "metadata": {},
   "source": [
    "### Parse bounds\n",
    "Load settings related to classifying antennas as good, suspect, or bad, then print what was loaded (or default)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ebbfd85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ant_metrics bounds for low correlation / dead antennas\n",
    "am_corr_bad = (0, float(os.environ.get(\"AM_CORR_BAD\", 0.3)))\n",
    "am_corr_suspect = (float(os.environ.get(\"AM_CORR_BAD\", 0.3)), float(os.environ.get(\"AM_CORR_SUSPECT\", 0.5)))\n",
    "\n",
    "# ant_metrics bounds for cross-polarized antennas\n",
    "am_xpol_bad = (-1, float(os.environ.get(\"AM_XPOL_BAD\", -0.1)))\n",
    "am_xpol_suspect = (float(os.environ.get(\"AM_XPOL_BAD\", -0.1)), float(os.environ.get(\"AM_XPOL_SUSPECT\", 0)))\n",
    "\n",
    "# bounds on solar altitude (in degrees)\n",
    "good_solar_altitude = (-90, float(os.environ.get(\"SUSPECT_SOLAR_ALTITUDE\", 0)))\n",
    "suspect_solar_altitude = (float(os.environ.get(\"SUSPECT_SOLAR_ALTITUDE\", 0)), 90)\n",
    "\n",
    "# bounds on zeros in spectra\n",
    "good_zeros_per_eo_spectrum = (0, int(os.environ.get(\"MAX_ZEROS_PER_EO_SPEC_GOOD\", 2)))\n",
    "suspect_zeros_per_eo_spectrum = (0, int(os.environ.get(\"MAX_ZEROS_PER_EO_SPEC_SUSPECT\", 8)))\n",
    "\n",
    "# bounds on autocorrelation power\n",
    "auto_power_good = (float(os.environ.get(\"AUTO_POWER_GOOD_LOW\", 5)), float(os.environ.get(\"AUTO_POWER_GOOD_HIGH\", 30)))\n",
    "auto_power_suspect = (float(os.environ.get(\"AUTO_POWER_SUSPECT_LOW\", 1)), float(os.environ.get(\"AUTO_POWER_SUSPECT_HIGH\", 60)))\n",
    "\n",
    "# bounds on autocorrelation slope\n",
    "auto_slope_good = (float(os.environ.get(\"AUTO_SLOPE_GOOD_LOW\", -0.4)), float(os.environ.get(\"AUTO_SLOPE_GOOD_HIGH\", 0.4)))\n",
    "auto_slope_suspect = (float(os.environ.get(\"AUTO_SLOPE_SUSPECT_LOW\", -0.6)), float(os.environ.get(\"AUTO_SLOPE_SUSPECT_HIGH\", 0.6)))\n",
    "\n",
    "# bounds on autocorrelation RFI\n",
    "auto_rfi_good = (0, float(os.environ.get(\"AUTO_RFI_GOOD\", 0.015)))\n",
    "auto_rfi_suspect = (0, float(os.environ.get(\"AUTO_RFI_SUSPECT\", 0.03)))\n",
    "\n",
    "# bounds on autocorrelation shape\n",
    "auto_shape_good = (0, float(os.environ.get(\"AUTO_SHAPE_GOOD\", 0.1)))\n",
    "auto_shape_suspect = (0, float(os.environ.get(\"AUTO_SHAPE_SUSPECT\", 0.2)))\n",
    "\n",
    "# bounds on chi^2 per antenna in omnical\n",
    "oc_cspa_good = (0, float(os.environ.get(\"OC_CSPA_GOOD\", 2)))\n",
    "oc_cspa_suspect = (0, float(os.environ.get(\"OC_CSPA_SUSPECT\", 3)))\n",
    "\n",
    "# print bounds\n",
    "for bound in ['am_corr_bad', 'am_corr_suspect', 'am_xpol_bad', 'am_xpol_suspect', \n",
    "              'good_solar_altitude', 'suspect_solar_altitude',\n",
    "              'good_zeros_per_eo_spectrum', 'suspect_zeros_per_eo_spectrum',\n",
    "              'auto_power_good', 'auto_power_suspect', 'auto_slope_good', 'auto_slope_suspect',\n",
    "              'auto_rfi_good', 'auto_rfi_suspect', 'auto_shape_good', 'auto_shape_suspect',\n",
    "              'oc_cspa_good', 'oc_cspa_suspect']:\n",
    "    print(f'{bound} = {eval(bound)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "105dc915",
   "metadata": {},
   "source": [
    "## Load sum and diff data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5d3725b",
   "metadata": {},
   "outputs": [],
   "source": [
    "hd = io.HERADataFastReader(SUM_FILE)\n",
    "data, _, _ = hd.read(read_flags=False, read_nsamples=False)\n",
    "hd_diff = io.HERADataFastReader(DIFF_FILE)\n",
    "diff_data, _, _ = hd_diff.read(read_flags=False, read_nsamples=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61f26bc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "ants = sorted(set([ant for bl in hd.bls for ant in utils.split_bl(bl)]))\n",
    "auto_bls = [bl for bl in data if (bl[0] == bl[1]) and (utils.split_pol(bl[2])[0] == utils.split_pol(bl[2])[1])]\n",
    "antpols = sorted(set([ant[1] for ant in ants]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e945a0ec",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# print basic information about the file\n",
    "print(f'File: {SUM_FILE}')\n",
    "print(f'JDs: {hd.times} ({np.median(np.diff(hd.times)) * 24 * 3600:.5f} s integrations)')\n",
    "print(f'LSTS: {hd.lsts * 12 / np.pi } hours')\n",
    "print(f'Frequencies: {len(hd.freqs)} {np.median(np.diff(hd.freqs)) / 1e6:.5f} MHz channels from {hd.freqs[0] / 1e6:.5f} to {hd.freqs[-1] / 1e6:.5f} MHz')\n",
    "print(f'Antennas: {len(hd.data_ants)}')\n",
    "print(f'Polarizations: {hd.pols}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39affb12",
   "metadata": {},
   "source": [
    "## Classify good, suspect, and bad antpols"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0450fb4",
   "metadata": {},
   "source": [
    "### Run `ant_metrics`\n",
    "\n",
    "This classifies antennas as cross-polarized, low-correlation, or dead. Such antennas are excluded from any calibration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bbb0ac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "am = ant_metrics.AntennaMetrics(SUM_FILE, DIFF_FILE, sum_data=data, diff_data=diff_data)\n",
    "am.iterative_antenna_metrics_and_flagging(crossCut=am_xpol_bad[1], deadCut=am_corr_bad[1])\n",
    "am.all_metrics = {}  # this saves time and disk by getting rid of per-iteration information we never use\n",
    "if SAVE_RESULTS:\n",
    "    am.save_antenna_metrics(AM_FILE, overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8e52c30",
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# Turn ant metrics into classifications\n",
    "totally_dead_ants = [ant for ant, i in am.xants.items() if i == -1]\n",
    "am_totally_dead = ant_class.AntennaClassification(good=[ant for ant in ants if ant not in totally_dead_ants], bad=totally_dead_ants)\n",
    "am_corr = ant_class.antenna_bounds_checker(am.final_metrics['corr'], bad=[am_corr_bad], suspect=[am_corr_suspect], good=[(0, 1)])\n",
    "am_xpol = ant_class.antenna_bounds_checker(am.final_metrics['corrXPol'], bad=[am_xpol_bad], suspect=[am_xpol_suspect], good=[(-1, 1)])\n",
    "ant_metrics_class = am_totally_dead + am_corr + am_xpol"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b294c33b",
   "metadata": {},
   "source": [
    "### Mark sun-up (or high solar altitude) data as suspect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bc848be",
   "metadata": {},
   "outputs": [],
   "source": [
    "min_sun_alt = np.min(utils.get_sun_alt(hd.times))\n",
    "solar_class = ant_class.antenna_bounds_checker({ant: min_sun_alt for ant in ants}, good=[good_solar_altitude], suspect=[suspect_solar_altitude])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcdb63f8",
   "metadata": {},
   "source": [
    "### Classify antennas responsible for 0s in visibilities as bad: \n",
    "\n",
    "This classifier looks for X-engine failure or packet loss specific to an antenna which causes either the even visibilities (or the odd ones, or both) to be 0s. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e64ed530",
   "metadata": {},
   "outputs": [],
   "source": [
    "zeros_class = ant_class.even_odd_zeros_checker(data, diff_data, good=good_zeros_per_eo_spectrum, suspect=suspect_zeros_per_eo_spectrum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bc9c521",
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete diffs to save memory\n",
    "del diff_data, hd_diff\n",
    "malloc_trim()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "102587ce",
   "metadata": {},
   "source": [
    "### Examine and classify autocorrelation power, slope, and RFI occpancy\n",
    "\n",
    "These classifiers look for antennas with too high or low power, to steep a slope, or too much excess RFI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bca07198",
   "metadata": {},
   "outputs": [],
   "source": [
    "auto_power_class = ant_class.auto_power_checker(data, good=auto_power_good, suspect=auto_power_suspect)\n",
    "auto_slope_class = ant_class.auto_slope_checker(data, good=auto_slope_good, suspect=auto_slope_suspect, edge_cut=100, filt_size=17)\n",
    "cache = {}\n",
    "auto_rfi_class = ant_class.auto_rfi_checker(data, good=auto_rfi_good, suspect=auto_rfi_suspect, \n",
    "                                            filter_half_widths=[RFI_DPSS_HALFWIDTH], nsig=RFI_NSIG, cache=cache)\n",
    "auto_class = auto_power_class + auto_slope_class + auto_rfi_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3e755bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "del cache\n",
    "malloc_trim()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9464e41e",
   "metadata": {},
   "source": [
    "### Find and flag RFI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c321e1d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute int_count for all unflagged autocorrelations averaged together\n",
    "int_time = 24 * 3600 * np.median(np.diff(data.times_by_bl[auto_bls[0][0:2]]))\n",
    "chan_res = np.median(np.diff(data.freqs))\n",
    "final_class = ant_metrics_class + zeros_class + auto_class\n",
    "int_count = int(int_time * chan_res) * (len(final_class.good_ants) + len(final_class.suspect_ants))\n",
    "avg_auto = {(-1, -1, 'ee'): np.mean([data[bl] for bl in auto_bls if final_class[utils.split_bl(bl)[0]] != 'bad'], axis=0)}\n",
    "# Flag RFI first with channel differences and then with DPSS\n",
    "antenna_flags, _ = xrfi.flag_autos(avg_auto, int_count=int_count, nsig=(RFI_NSIG * 5))\n",
    "_, rfi_flags = xrfi.flag_autos(avg_auto, int_count=int_count, flag_method='dpss_flagger',\n",
    "                               flags=antenna_flags, freqs=data.freqs, filter_centers=[0],\n",
    "                               filter_half_widths=[RFI_DPSS_HALFWIDTH], eigenval_cutoff=[1e-9], nsig=RFI_NSIG)\n",
    "malloc_trim()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8eae3de",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rfi_plot():\n",
    "    plt.figure(figsize=(12, 5), dpi=100)\n",
    "    plt.semilogy(hd.freqs / 1e6, np.where(rfi_flags, np.nan, avg_auto[(-1, -1, 'ee')])[1], label = 'Average Good or Suspect Autocorrelation', zorder=100)\n",
    "    plt.semilogy(hd.freqs / 1e6, np.where(False, np.nan, avg_auto[(-1, -1, 'ee')])[1], 'r', lw=.5, label=f'{np.sum(rfi_flags[0])} Channels Flagged for RFI')\n",
    "    plt.legend()\n",
    "    plt.xlabel('Frequency (MHz)')\n",
    "    plt.ylabel('Uncalibrated Autocorrelation')\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30928dbc",
   "metadata": {},
   "source": [
    "# *Figure 1: RFI Flagging*\n",
    "\n",
    "This figure shows RFI identified using the average of all autocorrelations---excluding bad antennas---for the first integration in the file. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de2fce7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "rfi_plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae2e2234",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def autocorr_plot(cls):    \n",
    "    fig, axes = plt.subplots(1, 2, figsize=(14, 5), dpi=100, sharey=True, gridspec_kw={'wspace': 0})\n",
    "    labels = []\n",
    "    colors = ['darkgreen', 'goldenrod', 'maroon']\n",
    "    for ax, pol in zip(axes, antpols):\n",
    "        for ant in cls.ants:\n",
    "            if ant[1] == pol:\n",
    "                color = colors[cls.quality_classes.index(cls[ant])]\n",
    "                ax.semilogy(np.mean(data[utils.join_bl(ant, ant)], axis=0), color=color, lw=.5)\n",
    "        ax.set_xlabel('Channel', fontsize=12)\n",
    "        ax.set_title(f'{utils.join_pol(pol, pol)}-Polarized Autos')\n",
    "\n",
    "    axes[0].set_ylabel('Raw Autocorrelation', fontsize=12)\n",
    "    axes[1].legend([matplotlib.lines.Line2D([0], [0], color=color) for color in colors], \n",
    "                   [cls.capitalize() for cls in auto_class.quality_classes], ncol=1, fontsize=12, loc='upper right', framealpha=1)\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32f9153c",
   "metadata": {},
   "source": [
    "### Classify antennas based on shapes, excluding RFI-contamined channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e005cb17",
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "auto_shape_class = ant_class.auto_shape_checker(data, good=auto_shape_good, suspect=auto_shape_suspect,\n",
    "                                                flag_spectrum=np.sum(rfi_flags, axis=0).astype(bool), antenna_class=final_class)\n",
    "auto_class += auto_shape_class"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d99ad916",
   "metadata": {},
   "source": [
    "# *Figure 2: Plot of autocorrelations with classifications*\n",
    "This figure shows a plot of all autocorrelations in the array, split by polarization. \n",
    "Antennas are classified based on their autocorrelations into good, suspect, and bad, by examining power, slope, and RFI-occupancy. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8f73053",
   "metadata": {},
   "outputs": [],
   "source": [
    "if PLOT: autocorr_plot(auto_class)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8d42f45",
   "metadata": {},
   "source": [
    "### Summarize antenna classification prior to redundant-baseline calibration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17b2b2bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_class = ant_metrics_class + solar_class + zeros_class + auto_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afd5cdcc",
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def array_class_plot(cls, extra_label=\"\"):\n",
    "    outriggers = [ant for ant in hd.data_ants if ant >= 320]\n",
    "\n",
    "    if len(outriggers) > 0:\n",
    "        fig, axes = plt.subplots(1, 2, figsize=(14, 6), dpi=100, gridspec_kw={'width_ratios': [2, 1]})\n",
    "        plot_antclass(hd.antpos, cls, ax=axes[0], ants=[ant for ant in hd.data_ants if ant < 320], legend=False, title=f'HERA Core{extra_label}')\n",
    "        plot_antclass(hd.antpos, cls, ax=axes[1], ants=outriggers, radius=50, title='Outriggers')\n",
    "    else:\n",
    "        fig, axes = plt.subplots(1, 1, figsize=(9, 6), dpi=100)\n",
    "        plot_antclass(hd.antpos, cls, ax=axes, ants=[ant for ant in hd.data_ants if ant < 320], legend=False, title=f'HERA Core{extra_label}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67427bcf",
   "metadata": {},
   "source": [
    "# *Figure 3: Summary of antenna classifications prior to calibration*\n",
    "This figure shows the location and classification of all antennas prior to calibration. \n",
    "Antennas are split along the diagonal, with ee-polarized antpols represented by the southeast half of each antenna and nn-polarized antpols represented by the northwest half.\n",
    "Outriggers are split from the core and shown at exaggerated size in the right-hand panel. This classification includes `ant_metrics`, a count of the zeros in the even or odd visibilities, and autocorrelation power, slope, and RFI occupancy.\n",
    "An antenna classified as bad in *any* classification will be considered bad. \n",
    "An antenna marked as suspect *any* in any classification will be considered suspect unless it is also classified as bad elsewhere."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19b7e8fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "if PLOT: array_class_plot(final_class)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e4fdac2",
   "metadata": {},
   "source": [
    "## Perform redundant-baseline calibration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10581f05",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_off_grid(reds, all_ants):\n",
    "    '''Returns AntennaClassification of all_ants where good ants are in reds while bad ants are not.'''\n",
    "    ants_in_reds = set([ant for red in reds for bl in red for ant in utils.split_bl(bl)])\n",
    "    on_grid = [ant for ant in all_ants if ant in ants_in_reds]\n",
    "    off_grid = [ant for ant in all_ants if ant not in ants_in_reds]\n",
    "    return ant_class.AntennaClassification(good=on_grid, bad=off_grid)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c81bb7a",
   "metadata": {},
   "source": [
    "### Perform iterative `redcal`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75361e1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "redcal_start = time.time()\n",
    "rc_settings = {'max_dims': OC_MAX_DIMS, 'oc_conv_crit': 1e-10, 'gain': 0.4, 'run_logcal': False,\n",
    "               'oc_maxiter': OC_MAXITER, 'check_after': OC_MAXITER, 'use_gpu': OC_USE_GPU}\n",
    "fr_settings = {'max_dims': OC_MAX_DIMS, 'min_dim_size': OC_MIN_DIM_SIZE, 'min_bl_cut': OC_MIN_BL_LEN, 'max_bl_cut': OC_MAX_BL_LEN}\n",
    "\n",
    "# figure out and filter reds and classify antennas based on whether or not they are on the main grid\n",
    "reds = redcal.get_reds(hd.data_antpos, pols=['ee', 'nn'], pol_mode='2pol')\n",
    "reds = redcal.filter_reds(reds, ex_ants=final_class.bad_ants, antpos=hd.data_antpos, **fr_settings)\n",
    "if OC_SKIP_OUTRIGGERS:\n",
    "    reds = redcal.filter_reds(reds, ex_ants=[ant for ant in ants if ant[0] >= 320])\n",
    "redcal_class = classify_off_grid(reds, ants)\n",
    "\n",
    "# perform first stage of redundant calibration, \n",
    "meta, sol = redcal.redundantly_calibrate(data, reds, **rc_settings)\n",
    "malloc_trim()\n",
    "max_dly = np.max(np.abs(list(meta['fc_meta']['dlys'].values())))\n",
    "med_cspa = {ant: np.median(meta['chisq_per_ant'][ant]) for ant in meta['chisq_per_ant']}\n",
    "cspa_class = ant_class.antenna_bounds_checker(med_cspa, good=np.array(oc_cspa_good)*5, suspect=np.array(oc_cspa_suspect)*5, bad=(0, np.inf))\n",
    "redcal_class += cspa_class\n",
    "print(f'Removing {cspa_class.bad_ants} for high chi^2.')\n",
    "\n",
    "# iteratively rerun redundant calibration\n",
    "for i in range(OC_MAX_RERUN):\n",
    "    # refilter reds and update classification to reflect new off-grid ants, if any\n",
    "    reds = redcal.filter_reds(reds, ex_ants=(final_class + redcal_class).bad_ants, antpos=hd.data_antpos, **fr_settings)\n",
    "    reds = sorted(reds, key=len, reverse=True)\n",
    "    redcal_class += classify_off_grid(reds, ants)\n",
    "    ants_in_reds = set([ant for red in reds for bl in red for ant in utils.split_bl(bl)])    \n",
    "   \n",
    "    # re-run redundant calibration using previous solution, updating bad and suspicious antennas\n",
    "    meta, sol = redcal.redundantly_calibrate(data, reds, sol0=sol, **rc_settings)\n",
    "    malloc_trim()\n",
    "    \n",
    "    # recompute chi^2 for bad antennas without bad antennas to make sure they are actually bad\n",
    "    med_cspa = {ant: np.median(meta['chisq_per_ant'][ant]) for ant in meta['chisq_per_ant']}\n",
    "    sol2 = redcal.RedSol(sol.reds, gains={ant: sol[ant] for ant in med_cspa if med_cspa[ant] <= oc_cspa_suspect[1]}, vis=sol.vis)\n",
    "    new_chisq_per_ant = {ant: np.array(meta['chisq_per_ant'][ant]) for ant in sol2.gains}\n",
    "    redcal.expand_omni_gains(sol2, reds, data, chisq_per_ant=new_chisq_per_ant)\n",
    "    med_cspa = {ant: np.min([med_cspa[ant], np.median(new_chisq_per_ant[ant])]) for ant in med_cspa}\n",
    "    \n",
    "    # remove bad antennas\n",
    "    cspa_class = ant_class.antenna_bounds_checker(med_cspa, good=oc_cspa_good, suspect=oc_cspa_suspect, bad=(0, np.inf))    \n",
    "    redcal_class += cspa_class\n",
    "    print(f'Removing {cspa_class.bad_ants} for high chi^2.')\n",
    "    if len(cspa_class.bad_ants) == 0:\n",
    "        break  # no new antennas to flag\n",
    "\n",
    "print(f'Finished redcal in {(time.time() - redcal_start) / 60:.2f} minutes.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bd57aa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_class += redcal_class"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d80e3151",
   "metadata": {},
   "source": [
    "### Expand solution to include calibratable baselines excluded from redcal (e.g. because they were too long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c02b6b06",
   "metadata": {},
   "outputs": [],
   "source": [
    "expanded_reds = redcal.get_reds(hd.data_antpos, pols=['ee', 'nn'], pol_mode='2pol')\n",
    "expanded_reds = redcal.filter_reds(expanded_reds, ex_ants=(ant_metrics_class + solar_class + zeros_class + auto_class).bad_ants, \n",
    "                                   max_dims=OC_MAX_DIMS, min_dim_size=OC_MIN_DIM_SIZE)\n",
    "if OC_SKIP_OUTRIGGERS:\n",
    "    expanded_reds = redcal.filter_reds(expanded_reds, ex_ants=[ant for ant in ants if ant[0] >= 320])\n",
    "redcal.expand_omni_vis(sol, expanded_reds, data, chisq=meta['chisq'], chisq_per_ant=meta['chisq_per_ant'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e16485f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now figure out flags, nsamples etc.\n",
    "omni_flags = {ant: ~np.isfinite(g) for ant, g in sol.gains.items()}\n",
    "vissol_flags = datacontainer.RedDataContainer({bl: ~np.isfinite(v) for bl, v in sol.vis.items()}, reds=sol.vis.reds)\n",
    "single_nsamples_array = np.ones((len(hd.times), len(hd.freqs)), dtype=float)\n",
    "nsamples = datacontainer.DataContainer({bl: single_nsamples_array for bl in data})\n",
    "vissol_nsamples = redcal.count_redundant_nsamples(nsamples, expanded_reds, good_ants=sol.gains)\n",
    "sol.make_sol_finite()        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed9a96d1",
   "metadata": {},
   "source": [
    "### Fix the `firstcal` delay slope degeneracy using RFI transmitters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cb2ed80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# find channels clearly contaminated by RFI\n",
    "not_bad_ants = [ant for ant in final_class.ants if final_class[ant] != 'bad']\n",
    "chan_flags = np.mean([xrfi.detrend_medfilt(data[utils.join_bl(ant, ant)], Kf=8, Kt=2) for ant in not_bad_ants], axis=(0, 1)) > 5\n",
    "\n",
    "# hardcoded RFI transmitters and their headings\n",
    "# channel: frequency (Hz), heading (rad), chi^2\n",
    "phs_sol = {359: ( 90744018.5546875, 0.7853981, 23.3),\n",
    "           360: ( 90866088.8671875, 0.7853981, 10.8),\n",
    "           385: ( 93917846.6796875, 0.7853981, 27.3),\n",
    "           386: ( 94039916.9921875, 0.7853981, 18.1),\n",
    "           400: ( 95748901.3671875, 6.0632738, 24.0),\n",
    "           441: (100753784.1796875, 0.7853981, 21.7),\n",
    "           442: (100875854.4921875, 0.7853981, 19.4),\n",
    "           455: (102462768.5546875, 6.0632738, 18.8),\n",
    "           456: (102584838.8671875, 6.0632738,  8.8),\n",
    "           471: (104415893.5546875, 0.7853981, 13.3),\n",
    "           484: (106002807.6171875, 6.0632738, 21.2),\n",
    "           485: (106124877.9296875, 6.0632738,  4.0),\n",
    "          1181: (191085815.4296875, 0.7853981, 26.3),\n",
    "          1182: (191207885.7421875, 0.7853981, 27.0),\n",
    "          1183: (191329956.0546875, 0.7853981, 25.6),\n",
    "          1448: (223678588.8671875, 2.6075219, 25.7),\n",
    "          1449: (223800659.1796875, 2.6075219, 22.6),\n",
    "          1450: (223922729.4921875, 2.6075219, 11.6),\n",
    "          1451: (224044799.8046875, 2.6075219,  5.9),\n",
    "          1452: (224166870.1171875, 2.6075219, 22.6),\n",
    "          1510: (231246948.2421875, 0.1068141, 23.9)}\n",
    "\n",
    "if not np.isclose(hd.freqs[0], 46920776.3671875, atol=0.001) or len(hd.freqs) != 1536:\n",
    "    # We have less frequencies than usual (maybe testing)\n",
    "    phs_sol = {np.argmin(np.abs(hd.freqs - freq)): (freq, heading, chisq) for chan, (freq, heading, chisq) in phs_sol.items() if hd.freqs[0] <= freq <= hd.freqs[-1]}\n",
    "\n",
    "\n",
    "rfi_chans = [chan for chan in phs_sol if chan_flags[chan]]\n",
    "print('Channels used for delay-slope calibration with RFI:', rfi_chans)\n",
    "rfi_angles = np.array([phs_sol[chan][1] for chan in rfi_chans])\n",
    "rfi_headings = np.array([np.cos(rfi_angles), np.sin(rfi_angles), np.zeros_like(rfi_angles)])\n",
    "rfi_chisqs = np.array([phs_sol[chan][2] for chan in rfi_chans])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1475452b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# resolve firstcal degeneracy with delay slopes set by RFI transmitters, update cal\n",
    "RFI_dly_slope_gains = abscal.RFI_delay_slope_cal([red for red in expanded_reds if red[0] in sol.vis], hd.antpos, sol.vis, hd.freqs, rfi_chans, rfi_headings, rfi_wgts=rfi_chisqs**-1,\n",
    "                                                 min_tau=-max_dly, max_tau=max_dly, delta_tau=0.1e-9, return_gains=True, gain_ants=sol.gains.keys())\n",
    "sol.gains = {ant: g * RFI_dly_slope_gains[ant] for ant, g in sol.gains.items()}\n",
    "apply_cal.calibrate_in_place(sol.vis, RFI_dly_slope_gains)\n",
    "malloc_trim()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb42028e",
   "metadata": {},
   "source": [
    "### Perform absolute amplitude calibration using a model of autocorrelations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd0b6a55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load simulated and then downsampled model of autocorrelations that includes receiver noise, then interpolate to upsample\n",
    "hd_model = io.HERADataFastReader(f'{HNBT_DATA}/SSM_autocorrelations_downsampled.uvh5')\n",
    "model, _, _ = hd_model.read(read_flags=False, read_nsamples=False)\n",
    "per_pol_interpolated_model = {}\n",
    "for bl in model:\n",
    "    sorted_lsts, lst_indices = np.unique(model.lsts, return_index=True)\n",
    "    periodic_model = np.vstack([model[bl][lst_indices, :], model[bl][lst_indices[0], :]])\n",
    "    periodic_lsts = np.append(sorted_lsts, sorted_lsts[0] + 2 * np.pi)\n",
    "    lst_interpolated = interpolate.CubicSpline(periodic_lsts, periodic_model, axis=0, bc_type='periodic')(data.lsts)\n",
    "    per_pol_interpolated_model[bl[2]] = interpolate.CubicSpline(model.freqs, lst_interpolated, axis=1)(data.freqs)\n",
    "model = {bl: per_pol_interpolated_model[bl[2]] for bl in auto_bls if utils.split_bl(bl)[0] not in final_class.bad_ants}    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca51f425",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run abscal and update omnical gains with abscal gains\n",
    "redcaled_autos = {bl: sol.calibrate_bl(bl, data[bl]) for bl in auto_bls if utils.split_bl(bl)[0] not in final_class.bad_ants}\n",
    "g_abscal = abscal.abs_amp_logcal(model, redcaled_autos, verbose=False, return_gains=True, gain_ants=sol.gains)\n",
    "sol.gains = {ant: g * g_abscal[ant] for ant, g in sol.gains.items()}\n",
    "apply_cal.calibrate_in_place(sol.vis, g_abscal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "848a4aad",
   "metadata": {},
   "outputs": [],
   "source": [
    "del hd_model, model, redcaled_autos, g_abscal\n",
    "malloc_trim()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de05f0a8",
   "metadata": {},
   "source": [
    "### Full absolute calibration of phase gradients\n",
    "If an `ABSCAL_MODEL_FILES_GLOB` is provided, try to perform a full absolute calibration of tip-tilt phase gradients across the array using that those model files. Specifically, this step calibrates omnical visbility solutions using unique baselines simulated with a model of the sky and HERA's beam."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "242c2ea9",
   "metadata": {},
   "outputs": [],
   "source": [
    "if ABSCAL_MODEL_FILES_GLOB is not None:\n",
    "    abscal_model_files = sorted(glob.glob(ABSCAL_MODEL_FILES_GLOB))\n",
    "else:\n",
    "    # try to find files on site\n",
    "    abscal_model_files = sorted(glob.glob('/mnt/sn1/abscal_models/H4C_1/abscal_files_unique_baselines/zen.2458894.?????.uvh5'))\n",
    "    if len(abscal_model_files) == 0:\n",
    "        # try to find files at NRAO\n",
    "        abscal_model_files = sorted(glob.glob('/lustre/aoc/projects/hera/zmartino/hera_calib_model/H4C_1/abscal_files_unique_baselines/zen.2458894.?????.uvh5'))\n",
    "print(f'Found {len(abscal_model_files)} abscal model files{\" in \" + os.path.dirname(abscal_model_files[0]) if len(abscal_model_files) > 0 else \"\"}.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79bc7dfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try to perform a full abscal of phase\n",
    "if len(abscal_model_files) == 0:\n",
    "    DO_FULL_ABSCAL = False\n",
    "    print('No model files found... not performing full absolute calibration of phase gradients.')\n",
    "else:\n",
    "    abscal_start = time.time()\n",
    "    # figure out which model files match the LSTs of the data\n",
    "    matched_model_files = sorted(set(abscal.match_times(SUM_FILE, abscal_model_files, filetype='uvh5')))\n",
    "    if len(matched_model_files) == 0:\n",
    "        DO_FULL_ABSCAL = False\n",
    "        print(f'No model files found matching the LSTs of this file after searching for {(time.time() - abscal_start) / 60:.2f} minutes. '\n",
    "              'Not performing full absolute calibration of phase gradients.')\n",
    "    else:\n",
    "        DO_FULL_ABSCAL = True\n",
    "        # figure out appropriate model times to load\n",
    "        hdm = io.HERAData(matched_model_files)\n",
    "        all_model_times, all_model_lsts = abscal.get_all_times_and_lsts(hdm, unwrap=True)\n",
    "        d2m_time_map = abscal.get_d2m_time_map(data.times, np.unwrap(data.lsts), all_model_times, all_model_lsts, extrap_limit=.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52c071cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "if DO_FULL_ABSCAL:\n",
    "    abscal_meta = {}\n",
    "    for pol in ['ee', 'nn']:\n",
    "        print(f'Performing absolute phase gradient calibration of {pol}-polarized visibility solutions...')\n",
    "        \n",
    "        # load matching times and baselines\n",
    "        unflagged_data_bls = [bl for bl in vissol_flags if not np.all(vissol_flags[bl])]\n",
    "        model_bls = copy.deepcopy(hdm.bls)\n",
    "        model_antpos = hdm.data_antpos\n",
    "        if len(matched_model_files) > 1:  # in this case, it's a dictionary\n",
    "            model_bls = list(set([bl for bls in list(hdm.bls.values()) for bl in bls]))\n",
    "            model_antpos = {ant: pos for antpos in hdm.data_antpos.values() for ant, pos in antpos.items()}\n",
    "        data_bls, model_bls, data_to_model_bl_map = abscal.match_baselines(unflagged_data_bls, model_bls, data.antpos, model_antpos=model_antpos, \n",
    "                                                                         pols=[pol], data_is_redsol=True, model_is_redundant=True, tol=1.0,\n",
    "                                                                         min_bl_cut=ABSCAL_MIN_BL_LEN, max_bl_cut=ABSCAL_MAX_BL_LEN, verbose=True)\n",
    "        model, model_flags, _ = io.partial_time_io(hdm, np.unique([d2m_time_map[time] for time in data.times]), bls=model_bls)\n",
    "        model_bls = [data_to_model_bl_map[bl] for bl in data_bls]\n",
    "        \n",
    "        # rephase model to match in lsts\n",
    "        model_blvecs = {bl: model.antpos[bl[0]] - model.antpos[bl[1]] for bl in model.keys()}\n",
    "        utils.lst_rephase(model, model_blvecs, model.freqs, data.lsts - model.lsts,\n",
    "                          lat=hdm.telescope_location_lat_lon_alt_degrees[0], inplace=True)\n",
    "\n",
    "        # run abscal and apply \n",
    "        abscal_meta[pol], delta_gains = abscal.complex_phase_abscal(sol.vis, model, sol.reds, data_bls, model_bls)\n",
    "        \n",
    "        # apply gains\n",
    "        sol.gains = {antpol : g * delta_gains.get(antpol, 1) for antpol, g in sol.gains.items()}\n",
    "        apply_cal.calibrate_in_place(sol.vis, delta_gains)            \n",
    "    \n",
    "    del hdm, model, model_flags, delta_gains\n",
    "    malloc_trim()\n",
    "    \n",
    "    print(f'Finished absolute calibration of tip-tilt phase slopes in {(time.time() - abscal_start) / 60:.2f} minutes.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b1c6fee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def smooth_gain_rbf_model(gain_estimates, nu_mhz, gain_estimate_weights=None,\n",
    "                          smoothing_scale=10.0, kernel_type='gaussian', smooth_inverse=True, return_model_data=False):\n",
    "    \"\"\"\"\n",
    "    Produces a smooth gain solution from noisy abscal gain estimates using a\n",
    "    Gaussian Radial Basis Function (RBF) model function in frequency for each time\n",
    "    integration individually. The model is defined to only vary on frequency scales\n",
    "    defined by `smoothing_scale` (equivalently, have only a fixed extent in delay).\n",
    "    A linear phase factor is divided out, then a set of series coefficients are\n",
    "    determined  as the weighted least-squares fit between the model and the\n",
    "    data (noisy gain estimates). The final smooth gain model is the product of\n",
    "    this RBF series and the linear phase factor.\n",
    "\n",
    "    Optionally, there are actually two fits performed to obtain the final smooth gain model.\n",
    "    After a smooth model is fit to the gain estimates, a second model fit is performed\n",
    "    on the inverse of the smooth gain model. The inverse of the fit to the inverse\n",
    "    of the first smooth model is what is returned as the final smooth gain solution.\n",
    "    The point of this is so that the it is the inverse of the gain solution that is\n",
    "    explicitly constrained in delay.\n",
    "\n",
    "    Parameters:\n",
    "    ----------\n",
    "    gain_estimates : Dictionary\n",
    "        Dictionary mapping antenna-polarization tuples e.g `(1, 'Jnn')` to ndarray's\n",
    "        of gain estimates with shape (N_times, N_freqs).\n",
    "    nu_mhz : ndarray\n",
    "        Frequencies in MHz corresponding to the gain samples.\n",
    "    gain_estimate_weights : Dictionary\n",
    "        Dictionary mapping every key in `gain_estimates` to an ndarray of weights\n",
    "        that is the same shape (N_times, Nfreqs) as the gain estimates. These weights\n",
    "        should be a measure of the relative quality of each sample along the frequency\n",
    "        axis. At minimum, the weights should be built from RFI flags (0 where flagged,\n",
    "        1 where unflagged), but may additionally include weighting based on\n",
    "        measures of abscal quality from `Z_sol` (see abscal.complex_phase_abscal)\n",
    "        or redundancy from omnical.\n",
    "    smoothing_scale : float\n",
    "        Units of MHz. Maximum frequency scale on which the smooth gain model is\n",
    "        allowed to vary. The equivalent effective band limit in delay is then:\n",
    "        (1e3 * 1 / smoothing_scale) nanoseconds, e.g 10MHz -> 100ns band limit.\n",
    "        The default of 10MHz is a good estimate of what real spectral structure\n",
    "        for HERA data can be fit in a single integration. Values that are smaller\n",
    "        than the size of the largest RFI gap will produce ill-conditioning and\n",
    "        poor-to-wildly-bad estimates of the gains in and around those gaps.\n",
    "    kernel_type : str, either 'gaussian' or 'inverse_quadratic'\n",
    "        Radial basis function to use. 'gaussian' should be the standard choice, but\n",
    "        'inverse_quadratic' could be useful to produce stable solutions over somewhat\n",
    "        larger RFI gaps (relative to the smoothing scale), at the cost of being somewhat\n",
    "        less smooth of a model.\n",
    "    smooth_inverse : bool\n",
    "        Default True. If True, the inverse of the returned gain solutions (i.e. 1/smooth_gains) is\n",
    "        is constrained to \n",
    "    return_model_data : bool\n",
    "        Default False. If True, addtionally return the smooth model parameters which\n",
    "        are a set of series coefficients and a linear phase slope (delay) for each\n",
    "        ant-pol and time.\n",
    "        \n",
    "    Returns:\n",
    "    -------\n",
    "    smooth_gains : Dictionary\n",
    "        Dictionary matching the input `gain_estimates` with the smooth gain model\n",
    "        evaluated at the frequencies `nu_mhz` for each time.\n",
    "\n",
    "    If `return_model_data` is `True`, additionally returns :\n",
    "        model_coefficients : Dictionary\n",
    "            Dictionary matching the input `gain_estimates` with the ndarray of complex\n",
    "            RBF series coeffcients for each time.\n",
    "        model_delays : Dictionary\n",
    "            Dictionary matching the input `gain_estimates` with the ndarray of\n",
    "            delays defining the linear phase factor for each time.\n",
    "    \"\"\"\n",
    "\n",
    "    def total_variation_approx(f, x):\n",
    "        return np.sum(np.abs(np.gradient(f, x)))\n",
    "\n",
    "    Ntimes = gain_estimates[next(iter(gain_estimates.keys()))].shape[0]\n",
    "    Nfreqs = nu_mhz.size\n",
    "\n",
    "    # get location of basis functions to use\n",
    "    delta_nu = 0.5*smoothing_scale\n",
    "    \n",
    "    nu0, nu1 = nu_mhz[0], nu_mhz[-1]\n",
    "    nu_mid = 0.5*(nu0 + nu1)\n",
    "    n_width = int((nu1 - nu0)/delta_nu / 2)\n",
    "    nu_nodes = nu_mid + delta_nu * np.arange(-n_width, n_width+1)\n",
    "    \n",
    "    if kernel_type == 'gaussian':\n",
    "        def gaussian(r, eps):\n",
    "            return np.exp(-(r/eps)**2)\n",
    "\n",
    "        phi_func = gaussian\n",
    "        eps_nu = 2.8 * delta_nu\n",
    "\n",
    "    elif kernel_type == 'inverse_quadratic':\n",
    "        def inverse_quadratic(r, eps):\n",
    "            return 1/(1 + (r/eps)**2)\n",
    "\n",
    "        phi_func = inverse_quadratic\n",
    "        eps_nu = 6.0 * delta_nu\n",
    "\n",
    "    # interpolation matrix\n",
    "    phi_mat = phi_func(nu_mhz[:,None] - nu_nodes[None,:], eps_nu)\n",
    "        \n",
    "    # initialize space for output smooth gains\n",
    "    smooth_gains = {a: np.empty((Ntimes, Nfreqs), dtype=complex) for a in gain_estimates.keys()}\n",
    "    \n",
    "    if return_model_data:\n",
    "        model_delays = {}\n",
    "        model_coefficients = {}\n",
    "        \n",
    "    # frequency sample spacing in Hz, used by fft_dly\n",
    "    delta_nu_hz = 1e6*(nu_mhz[1] - nu_mhz[0])\n",
    "\n",
    "    for a, g in gain_estimates.items():\n",
    "\n",
    "        wgts = gain_estimate_weights[a]\n",
    "        rfi_flags = np.where(np.abs(wgts) < 1e-14)[0]\n",
    "\n",
    "        # delays for all times\n",
    "        dlys = utils.fft_dly(g, delta_nu_hz, wgts=wgts)[0]\n",
    "        \n",
    "        if return_model_data:\n",
    "            model_delays[a] = dlys\n",
    "            model_coefficients[a] = np.empty((Ntimes, Nfreqs), dtype=complex)\n",
    "            \n",
    "        for i_t in range(Ntimes):\n",
    "\n",
    "            wgts_mat = np.diag(wgts[i_t])\n",
    "\n",
    "            # matrices used for least-squares fit\n",
    "            B = phi_mat.T @ wgts_mat\n",
    "            A = B @ phi_mat\n",
    "\n",
    "            # get linear phase factor for this time\n",
    "            linear_phasor = np.exp(1j * 2 * np.pi * (1e6 * nu_mhz) * dlys[i_t])\n",
    "\n",
    "            # estimate total variation with and without linear phase removed\n",
    "            nu_use = nu_mhz[~rfi_flags[i_t]]\n",
    "            tv_1 = total_variation_approx(g[i_t][~rfi_flags[i_t]], nu_use)\n",
    "            tv_2 = total_variation_approx((g[i_t]/linear_phasor)[~rfi_flags[i_t]], nu_use)\n",
    "\n",
    "            # check that the linear phase actually made things better\n",
    "            # if not, don't use it\n",
    "            if tv_2 > tv_1:\n",
    "                dlys[i_t] = 0.0\n",
    "                linear_phasor = np.ones(Nfreqs)\n",
    "\n",
    "            # first smooth gain model with linear phase remove\n",
    "            g0_coeffs = np.linalg.solve(A, B @ (g[i_t]/linear_phasor))\n",
    "\n",
    "            g0_smth = phi_mat @ g0_coeffs\n",
    "            \n",
    "            if smooth_inverse:\n",
    "                # second smooth model of the inverse\n",
    "                inv_g0_coeffs = np.linalg.solve(A, B @ (1/g0_smth))\n",
    "\n",
    "                g_smth = linear_phasor / (phi_mat @ inv_g0_coeffs)\n",
    "                \n",
    "                if return_model_data:\n",
    "                    model_coefficients[a][i_t] = inv_g0_coeffs\n",
    "                \n",
    "            else:\n",
    "                g_smth = linear_phasor * g0_smth\n",
    "                \n",
    "                if return_model_data:\n",
    "                    model_coefficients[a][i_t] = g0_coeffs\n",
    "                    \n",
    "            smooth_gains[a][i_t] = g_smth\n",
    "            \n",
    "\n",
    "    if return_model_data:\n",
    "        return smooth_gains, model_coefficients, model_delays\n",
    "    \n",
    "    else:\n",
    "        return smooth_gains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fe248e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def phase_dispersion_func(Z):\n",
    "    return -1*np.log(np.abs(Z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d88024a",
   "metadata": {},
   "outputs": [],
   "source": [
    "phase_dispersion = {pol: phase_dispersion_func(abscal_meta[pol]['Z_sol']) for pol in ['nn', 'ee']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ec20e44",
   "metadata": {},
   "outputs": [],
   "source": [
    "rfi_wgts = np.ones_like(rfi_flags)\n",
    "rfi_wgts[rfi_flags] = 0.0\n",
    "\n",
    "gain_est_weights = {a: rfi_wgts/phase_dispersion[a[1][1:]] for a in sol.gains}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "599a2f4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ref_ants = {}\n",
    "for pol in ['nn','ee']:\n",
    "#     ants_use = sorted([a[0] for a in sol.gains.keys() if a[1] == 'J'+pol and a not in final_class.bad_ants])\n",
    "    ants_use = sorted([a[0] for a in sol.gains.keys() if a[1] == 'J'+pol and a in final_class.good_ants])\n",
    "\n",
    "    r0 = np.mean([hd.antpos[a] for a in ants_use], axis=0)\n",
    "    \n",
    "    antpos_dist = [np.linalg.norm(hd.antpos[a] - r0) for a in ants_use]\n",
    "    ref_idx = np.argmin(antpos_dist)\n",
    "    \n",
    "    ref_ants[pol] = ants_use[ref_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "424fabf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "g_ref = {'nn': sol.gains[(ref_ants['nn'], 'Jnn')]/np.abs(sol.gains[(ref_ants['nn'], 'Jnn')]),\n",
    "         'ee': sol.gains[(ref_ants['ee'], 'Jee')]/np.abs(sol.gains[(ref_ants['ee'], 'Jee')])}\n",
    "\n",
    "for a, g in sol.gains.items():\n",
    "    pol = a[1]\n",
    "    \n",
    "    sol.gains[a] = g / g_ref[pol[1:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "853fd173",
   "metadata": {},
   "outputs": [],
   "source": [
    "nu_mhz = 1e-6*hd.freqs\n",
    "gain_estimates = copy.deepcopy(sol.gains)\n",
    "smooth_gains = smooth_gain_rbf_model(gain_estimates, nu_mhz, gain_estimate_weights=gain_est_weights, smoothing_scale=10.0, smooth_inverse=True)\n",
    "\n",
    "sol.gains = smooth_gains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3228070d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def redundant_group_plot():\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(14, 6), dpi=100, sharex='col', sharey='row', gridspec_kw={'hspace': 0, 'wspace': 0})\n",
    "    for i, pol in enumerate(['ee', 'nn']):\n",
    "        reds_here = redcal.get_reds(hd.data_antpos, pols=[pol], pol_mode='1pol')\n",
    "        red = sorted(redcal.filter_reds(reds_here, ex_ants=final_class.bad_ants), key=len, reverse=True)[0]\n",
    "        rc_data = {bl: sol.calibrate_bl(bl, data[bl]) for bl in red}\n",
    "        for bl in red:\n",
    "            axes[0, i].plot(hd.freqs/1e6, np.angle(rc_data[bl][0]), alpha=.5, lw=.5)\n",
    "            axes[1, i].semilogy(hd.freqs/1e6, np.abs(rc_data[bl][0]), alpha=.5, lw=.5)\n",
    "        axes[0, i].plot(hd.freqs / 1e6, np.angle(sol.vis[red[0]][0]), lw=1, c='k')\n",
    "        axes[1, i].semilogy(hd.freqs / 1e6, np.abs(sol.vis[red[0]][0]), lw=1, c='k', label=f'Baseline Group:\\n{red[0]}')\n",
    "        axes[1, i].set_xlabel('Frequency (MHz)')\n",
    "        axes[1, i].legend(loc='upper right')\n",
    "    axes[0, 0].set_ylabel('Visibility Phase (radians)')\n",
    "    axes[1, 0].set_ylabel('Visibility Amplitude (Jy)')\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58cdedf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def abscal_degen_plot():\n",
    "    if DO_FULL_ABSCAL:\n",
    "        fig, axes = plt.subplots(3, 1, figsize=(14, 6), dpi=100, sharex=True, gridspec_kw={'hspace': .05})\n",
    "\n",
    "        for ax, pol in zip(axes[:2], ['ee', 'nn']):\n",
    "            for kk in range(abscal_meta[pol]['Lambda_sol'].shape[-1]):\n",
    "                ax.plot(hd.freqs[~rfi_flags[0]] * 1e-6, abscal_meta[pol]['Lambda_sol'][0, ~rfi_flags[0], kk], '.', ms=1, label=f\"Component {kk}\")\n",
    "\n",
    "            ax.set_ylim(-np.pi-0.5, np.pi+0.5)\n",
    "            ax.set_xlabel('Frequency (MHz)')\n",
    "            ax.set_ylabel('Phase Gradient\\nVector Component')\n",
    "            ax.legend(markerscale=20, title=f'{pol}-polarization', loc='lower right')\n",
    "            ax.grid()\n",
    "            \n",
    "        for pol, color in zip(['ee', 'nn'], ['b', 'r']):\n",
    "            axes[2].plot(hd.freqs[~rfi_flags[0]]*1e-6, abscal_meta[pol]['Z_sol'].real[0, ~rfi_flags[0]], '.', ms=1, label=pol, color=color)\n",
    "        axes[2].set_ylim(-.25, 1.05)\n",
    "        axes[2].set_ylabel('Re[Z($\\\\nu$)]')\n",
    "        axes[2].legend(markerscale=20, loc='lower right')\n",
    "        axes[2].grid()            \n",
    "        plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61aca081",
   "metadata": {},
   "source": [
    "# *Figure 4: Redundant calibration of a single baseline group*\n",
    "The results of a redundant-baseline calibration of a single integration and a single group, the one with the highest redundancy in each polarization after antenna classification and excision based on the above, plus the removal of antennas with high chi^2 per antenna. The black line is the redundant visibility solution. Each thin colored line is a different baseline group. Phases are shown in the top row, amplitudes in the bottom, ee-polarized visibilities in the left column, and nn-polarized visibilities in the right."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3df7a51",
   "metadata": {},
   "outputs": [],
   "source": [
    "if PLOT: redundant_group_plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfd8e047",
   "metadata": {},
   "source": [
    "# *Figure 5: Absolute calibration of `redcal` degeneracies*\n",
    "This figure shows the per-frequency phase gradient solutions across the array for both polarizations and all components of the degenerate subspace of redundant-baseline calibraton. While full HERA only has two such tip-tilt degeneracies, a subset of HERA can have up to `OC_MAX_DIMS` (depending on antenna flagging). In addition to the absolute amplitude, this is the full set of the calibration degrees of freedom not constrainted by `redcal`. This figure also includes a plot of $Re[Z(\\nu)]$, the complex objective function which varies from -1 to 1 and indicates how well the data and the absolute calibration model have been made to agree. Perfect agreement is 1.0 and good agreement is anything above $\\sim$0.5 Decorrelation yields values closer to 0, where anything below $\\sim$0.3 is suspect."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e401bc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "if PLOT: abscal_degen_plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21970839",
   "metadata": {},
   "source": [
    "### Attempt to calibrate some flagged antennas\n",
    "This attempts to calibrate bad antennas using information from good or suspect antennas without allowing bad antennas to affect their calibration. However, introducing 0s in gains or infs/nans in gains or visibilities can create problems down the line, so those are removed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b51734c",
   "metadata": {},
   "outputs": [],
   "source": [
    "expanded_reds = redcal.get_reds(hd.data_antpos, pols=['ee', 'nn'], pol_mode='2pol')\n",
    "sol.vis.build_red_keys(expanded_reds)\n",
    "redcal.expand_omni_gains(sol, expanded_reds, data, chisq_per_ant=meta['chisq_per_ant'])\n",
    "redcal.expand_omni_vis(sol, expanded_reds, data)\n",
    "\n",
    "# Replace zeros in gains and infs/nans in gains/sols\n",
    "for ant in sol.gains:\n",
    "    zeros_in_gains = (sol.gains[ant] == 0)\n",
    "    if ant in omni_flags:\n",
    "        omni_flags[ant][zeros_in_gains] = True\n",
    "    sol.gains[ant][zeros_in_gains] = 1.0 + 0.0j\n",
    "sol.make_sol_finite()\n",
    "malloc_trim()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "933cbdf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def array_chisq_plot():\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(14, 5), dpi=100)\n",
    "    for ax, pol in zip(axes, ['ee', 'nn']):\n",
    "        ants_to_plot = set([ant for ant in meta['chisq_per_ant'] if utils.join_pol(ant[1], ant[1]) == pol])\n",
    "        cspas = np.array([np.median(meta['chisq_per_ant'][ant]) for ant in ants_to_plot])\n",
    "        xpos = [hd.antpos[ant[0]][0] for ant in ants_to_plot]\n",
    "        ypos = [hd.antpos[ant[0]][1] for ant in ants_to_plot]\n",
    "        scatter = ax.scatter(xpos, ypos, s=300, c=cspas, lw=.25, edgecolors=np.where(np.isfinite(cspas) & (cspas > 0), 'none', 'k'), \n",
    "                             norm=matplotlib.colors.LogNorm(vmin=1, vmax=oc_cspa_suspect[1]))\n",
    "        for ant in ants_to_plot:\n",
    "            ax.text(hd.antpos[ant[0]][0], hd.antpos[ant[0]][1], ant[0], va='center', ha='center', fontsize=8,\n",
    "                    c=('r' if ant in final_class.bad_ants else 'w'))\n",
    "        plt.colorbar(scatter, ax=ax, extend='both')\n",
    "        ax.axis('equal')\n",
    "        ax.set_xlabel('East-West Position (meters)')\n",
    "        ax.set_ylabel('North-South Position (meters)')\n",
    "        ax.set_title(f'{pol}-pol $\\\\chi^2$ / Antenna (Red is Flagged)')\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4deeb7fa",
   "metadata": {},
   "source": [
    "# *Figure 6: chi^2 per antenna across the array*\n",
    "\n",
    "This plot shows median (taken over time and frequency) of the normalized chi^2 per antenna. \n",
    "The expectation value for this quantity when the array is perfectly redundant is 1.0. \n",
    "Antennas that are classified as bad for any reason have their numbers shown in red. \n",
    "Some of those antennas were classified as bad during redundant calibration for high chi^2. \n",
    "Some of those antennas were originally excluded from redundant calibration because they were classified as bad earlier for some reason. \n",
    "See [here for more details.](#Attempt-to-calibrate-some-flagged-antennas)\n",
    "Note that the color scale saturates at below 1 and above 10. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74083166",
   "metadata": {},
   "outputs": [],
   "source": [
    "if PLOT: array_chisq_plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "241c0a22",
   "metadata": {},
   "source": [
    "# *Figure 7: Summary of antenna classifications after redundant calibration*\n",
    "\n",
    "This figure is the same as [Figure 2](#Figure-2:-Summary-of-antenna-classifications-prior-to-calibration), except that it now includes additional suspect or bad antennas based on redundant calibration.\n",
    "This can include antennas with high chi^2, but it can also include antennas classified as \"bad\" because they would add extra degeneracies to calibration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "605d5142",
   "metadata": {},
   "outputs": [],
   "source": [
    "if PLOT: array_class_plot(final_class, extra_label=\", Post-Redcal\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "592a378e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "to_show = {'Antenna': [f'{ant[0]}{ant[1][-1]}' for ant in ants]}\n",
    "classes = {'Antenna': [final_class[ant] if ant in final_class else '-' for ant in ants]}\n",
    "to_show['Dead?'] = [{'good': 'No', 'bad': 'Yes'}[am_totally_dead[ant]] if (ant in am_totally_dead) else '' for ant in ants]\n",
    "classes['Dead?'] = [am_totally_dead[ant] if (ant in am_totally_dead) else '' for ant in ants]\n",
    "for title, ac in [('Low Correlation', am_corr),\n",
    "                  ('Cross-Polarized', am_xpol),\n",
    "                  ('Solar Alt', solar_class),\n",
    "                  ('Even/Odd Zeros', zeros_class),\n",
    "                  ('Autocorr Power', auto_power_class),\n",
    "                  ('Autocorr Slope', auto_slope_class),\n",
    "                  ('RFI in Autos', auto_rfi_class),\n",
    "                  ('Autocorr Shape', auto_shape_class)]:\n",
    "    to_show[title] = [f'{ac._data[ant]:.2G}' if (ant in ac._data) else '' for ant in ants]\n",
    "    classes[title] = [ac[ant] if ant in ac else '' for ant in ants]\n",
    "    \n",
    "to_show['Redcal chi^2'] = [f'{np.median(meta[\"chisq_per_ant\"][ant]):.3G}' if (ant in meta['chisq_per_ant']) else '-' for ant in ants]\n",
    "classes['Redcal chi^2'] = [redcal_class[ant] if ant in redcal_class else '' for ant in ants]\n",
    "\n",
    "df = pd.DataFrame(to_show)\n",
    "df_classes = pd.DataFrame(classes)\n",
    "colors = {'good': 'darkgreen', 'suspect': 'goldenrod', 'bad': 'maroon'}\n",
    "df_colors = df_classes.applymap(lambda x: f'background-color: {colors.get(x, None)}')\n",
    "\n",
    "table = df.style.hide_index() \\\n",
    "                .apply(lambda x: pd.DataFrame(df_colors.values, columns=x.columns), axis=None) \\\n",
    "                .set_properties(subset=['Antenna'], **{'font-weight': 'bold', 'border-right': \"3pt solid black\"}) \\\n",
    "                .set_properties(subset=df.columns[1:], **{'border-left': \"1pt solid black\"}) \\\n",
    "                .set_properties(**{'text-align': 'center', 'color': 'white'})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d812fe1",
   "metadata": {},
   "source": [
    "# *Table 1: Complete summary of per-antenna classifications*\n",
    "\n",
    "This table summarizes the results of the various classifications schemes detailed above. \n",
    "As before, <font color='#006400'>green is good</font>, <font color='#DAA520'>yellow is suspect</font>, and <font color='#800000'>red is bad</font>. The color for each antenna (first column) is the final summary of all other classifications.\n",
    "Antennas missing from redcal $\\chi^2$ were excluded redundant-baseline calibration, either because they were flagged by `ant_metrics` or the even/odd zeros check, or because they would add unwanted extra degeneracies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aacbd4c3",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "HTML(table.render())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dda087b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save antenna classification table as a csv\n",
    "if SAVE_RESULTS:\n",
    "    for ind, col in zip(np.arange(len(df.columns), 0, -1), df_classes.columns[::-1]):\n",
    "        df.insert(int(ind), col + ' Class', df_classes[col])\n",
    "    df.to_csv(ANTCLASS_FILE)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3acdc23",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print('Final Ant-Pol Classification:\\n\\n', final_class)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46cbe21a",
   "metadata": {},
   "source": [
    "## Save calibration solutions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09348a58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# update flags in omnical gains and visibility solutions\n",
    "for ant in omni_flags:\n",
    "    omni_flags[ant] |= rfi_flags\n",
    "for bl in vissol_flags:\n",
    "    vissol_flags[bl] |= rfi_flags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6600ee32",
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "if SAVE_RESULTS:\n",
    "    add_to_history = 'Produced by file_calibration notebook with the following environment:\\n' + '=' * 65 + '\\n' + os.popen('conda env export').read() + '=' * 65    \n",
    "    \n",
    "    hd_vissol = io.HERAData(SUM_FILE)\n",
    "    hc_omni = hd_vissol.init_HERACal(gain_convention='divide', cal_style='redundant')\n",
    "    hc_omni.update(gains=sol.gains, flags=omni_flags, quals=meta['chisq_per_ant'], total_qual=meta['chisq'])\n",
    "    hc_omni.history += add_to_history\n",
    "    hc_omni.write_calfits(OMNICAL_FILE, clobber=True)\n",
    "    del hc_omni\n",
    "    malloc_trim()\n",
    "    \n",
    "    # output results, harmonizing keys over polarizations\n",
    "    all_reds = redcal.get_reds(hd.data_antpos, pols=['ee', 'nn'], pol_mode='2pol')\n",
    "    bl_to_red_map = {bl: red[0] for red in all_reds for bl in red}\n",
    "    hd_vissol.read(bls=[bl_to_red_map[bl] for bl in sol.vis], return_data=False)\n",
    "    hd_vissol.empty_arrays()\n",
    "    hd_vissol.history += add_to_history\n",
    "    hd_vissol.update(data={bl_to_red_map[bl]: sol.vis[bl] for bl in sol.vis}, \n",
    "                     flags={bl_to_red_map[bl]: vissol_flags[bl] for bl in vissol_flags}, \n",
    "                     nsamples={bl_to_red_map[bl]: vissol_nsamples[bl] for bl in vissol_nsamples})\n",
    "    hd_vissol.write_uvh5(OMNIVIS_FILE, clobber=True)\n",
    "    del hd_vissol\n",
    "    malloc_trim()    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c9ba18d",
   "metadata": {},
   "source": [
    "### Output fully flagged calibration file if `OMNICAL_FILE` is not written"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46e8a62d",
   "metadata": {},
   "outputs": [],
   "source": [
    "if SAVE_RESULTS and not os.path.exists(OMNICAL_FILE):\n",
    "    print(f'WARNING: No calibration file produced at {OMNICAL_FILE}. Creating a fully-flagged placeholder calibration file.')\n",
    "    hd_writer = io.HERAData(SUM_FILE)\n",
    "    io.write_cal(OMNICAL_FILE, freqs=hd_writer.freqs, times=hd_writer.times,\n",
    "                 gains={ant: np.ones((hd_writer.Ntimes, hd_writer.Nfreqs), dtype=np.complex64) for ant in ants},\n",
    "                 flags={ant: np.ones((len(data.times), len(data.freqs)), dtype=bool) for ant in ants},\n",
    "                 quality=None, total_qual=None, outdir='', overwrite=True, history=utils.history_string(add_to_history), \n",
    "                 x_orientation=hd_writer.x_orientation, telescope_location=hd_writer.telescope_location, lst_array=np.unique(hd_writer.lsts),\n",
    "                 antenna_positions=np.array([hd_writer.antenna_positions[hd_writer.antenna_numbers == antnum].flatten() for antnum in set(ant[0] for ant in ants)]),\n",
    "                 antnums2antnames=dict(zip(hd_writer.antenna_numbers, hd_writer.antenna_names)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d955c8e",
   "metadata": {},
   "source": [
    "### Output empty visibility file if `OMNIVIS_FILE` is not written"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1882bdb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "if SAVE_RESULTS and not os.path.exists(OMNIVIS_FILE):\n",
    "    print(f'WARNING: No omnivis file produced at {OMNIVIS_FILE}. Creating an empty visibility solution file.')\n",
    "    hd_writer = io.HERAData(SUM_FILE)\n",
    "    hd_writer.initialize_uvh5_file(OMNIVIS_FILE, clobber=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e45767b6",
   "metadata": {},
   "source": [
    "## TODO: Perform nucal"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f52a30f9",
   "metadata": {},
   "source": [
    "## Metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78d18d26",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for repo in ['pyuvdata', 'hera_cal', 'hera_filters', 'hera_qm', 'hera_notebook_templates']:\n",
    "    exec(f'from {repo} import __version__')\n",
    "    print(f'{repo}: {__version__}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23fd861c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Finished execution in {(time.time() - tstart) / 60:.2f} minutes.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0f88b62",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e566185",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "main",
   "language": "python",
   "name": "main"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "315.391px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  },
  "vscode": {
   "interpreter": {
    "hash": "1b3d6c34b4c0959d1c58ed6600dba8a283b5217fb9e451bb3c52ef7f338a0cef"
   }
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
