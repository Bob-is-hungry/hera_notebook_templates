{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Nightly Per-Antenna Quality Summary Notebook\n",
    "\n",
    "**Josh Dillon**, Last Revised February 2021\n",
    "\n",
    "This notebooks brings together as much information as possible from `ant_metrics`, `auto_metrics` and `redcal` to help figure out which antennas are working properly and summarizes it in a single giant table. It is meant to be lightweight and re-run as often as necessary over the night, so it can be run when any of those is done and then be updated when another one completes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-20T00:41:21.035483Z",
     "start_time": "2021-02-20T00:41:19.743917Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_rows', 1000)\n",
    "from hera_qm.metrics_io import load_metric_file\n",
    "from hera_cal import utils, io, redcal\n",
    "import glob\n",
    "import os\n",
    "import h5py\n",
    "from copy import deepcopy\n",
    "from IPython.display import display, HTML\n",
    "from hera_notebook_templates.utils import status_colors\n",
    "\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-20T00:41:21.040382Z",
     "start_time": "2021-02-20T00:41:19.706Z"
    }
   },
   "outputs": [],
   "source": [
    "# If you want to run this notebook locally, copy the output of the next cell into the first few lines of this cell.\n",
    "\n",
    "# JD = \"2459122\"\n",
    "# data_path = '/lustre/aoc/projects/hera/H4C/2459122'\n",
    "# ant_metrics_ext = \".ant_metrics.hdf5\"\n",
    "# redcal_ext = \".maybe_good.omni.calfits\"\n",
    "# nb_outdir = '/lustre/aoc/projects/hera/H4C/h4c_software/H4C_Notebooks/_rtp_summary_'\n",
    "# os.environ[\"JULIANDATE\"] = JD\n",
    "# os.environ[\"DATA_PATH\"] = data_path\n",
    "# os.environ[\"ANT_METRICS_EXT\"] = ant_metrics_ext\n",
    "# os.environ[\"REDCAL_EXT\"] = redcal_ext\n",
    "# os.environ[\"NB_OUTDIR\"] = nb_outdir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-20T00:41:21.041903Z",
     "start_time": "2021-02-20T00:41:19.708Z"
    }
   },
   "outputs": [],
   "source": [
    "# Use environment variables to figure out path to data\n",
    "JD = os.environ['JULIANDATE']\n",
    "data_path = os.environ['DATA_PATH']\n",
    "ant_metrics_ext = os.environ['ANT_METRICS_EXT']\n",
    "redcal_ext = os.environ['REDCAL_EXT']\n",
    "nb_outdir = os.environ['NB_OUTDIR']\n",
    "print(f'JD = \"{JD}\"')\n",
    "print(f'data_path = \"{data_path}\"')\n",
    "print(f'ant_metrics_ext = \"{ant_metrics_ext}\"')\n",
    "print(f'redcal_ext = \"{redcal_ext}\"')\n",
    "print(f'nb_outdir = \"{nb_outdir}\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from astropy.time import Time\n",
    "utc = Time(JD, format='jd').datetime\n",
    "print(f'Date: {utc.month}-{utc.day}-{utc.year}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Auto Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-20T00:41:21.043653Z",
     "start_time": "2021-02-20T00:41:19.710Z"
    }
   },
   "outputs": [],
   "source": [
    "use_auto_metrics = False\n",
    "\n",
    "# find the auto_metrics file\n",
    "glob_str = os.path.join(data_path, f'zen.{JD}*.auto_metrics.h5')\n",
    "auto_metrics_file = sorted(glob.glob(glob_str))\n",
    "\n",
    "# if it exists, load and extract relevant information\n",
    "if len(auto_metrics_file) > 0:\n",
    "    auto_metrics_file = auto_metrics_file[0]\n",
    "    print(f'Found auto_metrics results file at {auto_metrics_file}.')\n",
    "    \n",
    "    auto_metrics = load_metric_file(auto_metrics_file)\n",
    "    mean_round_modz_cut = auto_metrics['parameters']['mean_round_modz_cut']\n",
    "    auto_ex_ants = auto_metrics['ex_ants']['r2_ex_ants']\n",
    "    \n",
    "    use_auto_metrics = True\n",
    "else:\n",
    "    print(f'No files found matching glob {glob_str}. Skipping auto_metrics.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Ant Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-20T00:41:21.045338Z",
     "start_time": "2021-02-20T00:41:19.712Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "use_ant_metrics = False\n",
    "\n",
    "# get a list of all ant_metrics files\n",
    "glob_str = os.path.join(data_path, f'zen.{JD}.?????.sum{ant_metrics_ext}')\n",
    "ant_metrics_files = sorted(glob.glob(glob_str))\n",
    "\n",
    "# if they exist, load as many of them as possible\n",
    "if len(ant_metrics_files) > 0:\n",
    "    print(f'Found {len(ant_metrics_files)} ant_metrics files matching glob {glob_str}')\n",
    "    ant_metrics_apriori_exants = {}\n",
    "    ant_metrics_xants_dict = {}\n",
    "    ant_metrics_dead_ants_dict = {}\n",
    "    ant_metrics_crossed_ants_dict = {}\n",
    "    ant_metrics_dead_metrics = {}\n",
    "    ant_metrics_crossed_metrics = {}\n",
    "    dead_cuts = {}\n",
    "    crossed_cuts = {}\n",
    "    for amf in ant_metrics_files:\n",
    "        with h5py.File(amf, \"r\") as infile: # use h5py directly since it's much faster than load_metric_file\n",
    "            # get out results for this file\n",
    "            dead_cuts[amf] = infile['Metrics']['dead_ant_cut'][()]\n",
    "            crossed_cuts[amf] = infile['Metrics']['cross_pol_cut'][()]\n",
    "            xants = infile['Metrics']['xants'][:]\n",
    "            dead_ants = infile['Metrics']['dead_ants'][:]\n",
    "            crossed_ants = infile['Metrics']['crossed_ants'][:]        \n",
    "            try:\n",
    "                # look for ex_ants in history\n",
    "                ex_ants_string = infile['Header']['history'][()].decode()\n",
    "                ex_ants_string = ex_ants_string.split('--apriori_xants')[1]\n",
    "                ex_ants_string = ex_ants_string.split('--')[0].strip()\n",
    "            except:\n",
    "                ex_ants_string = ''\n",
    "                    \n",
    "            # This only works for the new correlation-matrix-based ant_metrics\n",
    "            if 'corr' in infile['Metrics']['final_metrics'] and 'corrXPol' in infile['Metrics']['final_metrics']:\n",
    "                ant_metrics_dead_metrics[amf] = {eval(ant): infile['Metrics']['final_metrics']['corr'][ant][()]\n",
    "                                                 for ant in infile['Metrics']['final_metrics']['corr']}\n",
    "                ant_metrics_crossed_metrics[amf] = {eval(ant): infile['Metrics']['final_metrics']['corrXPol'][ant][()]\n",
    "                                                    for ant in infile['Metrics']['final_metrics']['corrXPol']}                       \n",
    "            else:\n",
    "                raise(KeywordError)\n",
    "        \n",
    "        # organize results by file\n",
    "        ant_metrics_xants_dict[amf] = [(int(ant[0]), ant[1].decode()) for ant in xants]\n",
    "        ant_metrics_dead_ants_dict[amf] = [(int(ant[0]), ant[1].decode()) for ant in dead_ants]\n",
    "        ant_metrics_crossed_ants_dict[amf] = [(int(ant[0]), ant[1].decode()) for ant in crossed_ants]\n",
    "        ant_metrics_apriori_exants[amf] = [int(ant) for ant in ex_ants_string.split()]\n",
    "    \n",
    "    dead_cut = np.median(list(dead_cuts.values()))\n",
    "    crossed_cut = np.median(list(crossed_cuts.values()))\n",
    "        \n",
    "    use_ant_metrics = True\n",
    "else:\n",
    "    print(f'No files found matching glob {glob_str}. Skipping ant_metrics.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load chi^2 info from redcal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-20T00:41:21.047007Z",
     "start_time": "2021-02-20T00:41:19.714Z"
    }
   },
   "outputs": [],
   "source": [
    "use_redcal = False\n",
    "glob_str = os.path.join(data_path, f'zen.{JD}.?????.sum{redcal_ext}')\n",
    "\n",
    "redcal_files = sorted(glob.glob(glob_str))\n",
    "if len(redcal_files) > 0:\n",
    "    print(f'Found {len(redcal_files)} ant_metrics files matching glob {glob_str}')\n",
    "    post_redcal_ant_flags_dict = {}\n",
    "    flagged_by_redcal_dict = {}\n",
    "    cspa_med_dict = {}\n",
    "    for cal in redcal_files:\n",
    "        hc = io.HERACal(cal)\n",
    "        _, flags, cspa, chisq = hc.read()\n",
    "        cspa_med_dict[cal] = {ant: np.nanmedian(cspa[ant], axis=1) for ant in cspa}\n",
    "\n",
    "        post_redcal_ant_flags_dict[cal] = {ant: np.all(flags[ant]) for ant in flags}\n",
    "        # check history to distinguish antennas flagged going into redcal from ones flagged during redcal\n",
    "        tossed_antenna_lines =  hc.history.replace('\\n','').split('Throwing out antenna ')[1:]\n",
    "        flagged_by_redcal_dict[cal] = sorted([int(line.split(' ')[0]) for line in tossed_antenna_lines])\n",
    "        \n",
    "    use_redcal = True\n",
    "else:\n",
    "    print(f'No files found matching glob {glob_str}. Skipping redcal chisq.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Figure out some general properties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-20T00:41:21.048455Z",
     "start_time": "2021-02-20T00:41:19.715Z"
    }
   },
   "outputs": [],
   "source": [
    "# Parse some general array properties, taking into account the fact that we might be missing some of the metrics\n",
    "ants = []\n",
    "pols = []\n",
    "antpol_pairs = []\n",
    "\n",
    "if use_auto_metrics:\n",
    "    ants = sorted(set(bl[0] for bl in auto_metrics['modzs']['r2_shape_modzs']))\n",
    "    pols = sorted(set(bl[2] for bl in auto_metrics['modzs']['r2_shape_modzs']))\n",
    "if use_ant_metrics:\n",
    "    antpol_pairs = sorted(set([antpol for dms in ant_metrics_dead_metrics.values() for antpol in dms.keys()]))\n",
    "    antpols = sorted(set(antpol[1] for antpol in antpol_pairs))\n",
    "    ants = sorted(set(antpol[0] for antpol in antpol_pairs) | set(ants))\n",
    "    pols = sorted(set(utils.join_pol(ap, ap) for ap in antpols) | set(pols))\n",
    "if use_redcal:\n",
    "    antpol_pairs = sorted(set([ant for cspa in cspa_med_dict.values() for ant in cspa.keys()]) | set(antpol_pairs))\n",
    "    antpols = sorted(set(antpol[1] for antpol in antpol_pairs))\n",
    "    ants = sorted(set(antpol[0] for antpol in antpol_pairs) | set(ants))\n",
    "    pols = sorted(set(utils.join_pol(ap, ap) for ap in antpols) | set(pols))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load a priori antenna statuses and node numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-20T00:41:21.049880Z",
     "start_time": "2021-02-20T00:41:19.718Z"
    }
   },
   "outputs": [],
   "source": [
    "# try to load a priori antenna statusesm but fail gracefully if this doesn't work.\n",
    "a_priori_statuses = {ant: 'Not Found' for ant in ants}\n",
    "nodes = {ant: np.nan for ant in ants}\n",
    "try:\n",
    "    from hera_mc import cm_active, cm_hookup\n",
    "\n",
    "    # get apriori antenna status\n",
    "    h = cm_active.ActiveData(at_date=JD)\n",
    "    h.load_apriori()    \n",
    "    for ant_name in h.apriori:\n",
    "        ant = int(\"\".join(filter(str.isdigit, ant_name)))\n",
    "        if ant in a_priori_statuses:\n",
    "            a_priori_statuses[ant] = h.apriori[ant_name].status\n",
    "    \n",
    "    # get node numbers\n",
    "    h = cm_hookup.Hookup()\n",
    "    hookup = h.get_hookup('default')\n",
    "    for ant_name in hookup:\n",
    "        ant = int(\"\".join(filter(str.isdigit, ant_name)))\n",
    "        if ant in nodes:\n",
    "            nodes[ant] = int(hookup[ant_name].get_part_from_type('node')['E<ground'][1:])\n",
    "    \n",
    "except Exception as err:\n",
    "    print(f'Could not load node numbers and a priori antenna statuses.\\nEncountered {type(err)} with message: {err}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summarize auto metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-20T00:41:21.051453Z",
     "start_time": "2021-02-20T00:41:19.720Z"
    }
   },
   "outputs": [],
   "source": [
    "if use_auto_metrics:\n",
    "    # Parse modzs\n",
    "    modzs_to_check = {'Shape': 'r2_shape_modzs', 'Power': 'r2_power_modzs', \n",
    "                      'Temporal Variability': 'r2_temp_var_modzs', 'Temporal Discontinuties': 'r2_temp_diff_modzs'}\n",
    "    worst_metrics = []\n",
    "    worst_zs = []\n",
    "    all_modzs = {}\n",
    "    binary_flags = {rationale: [] for rationale in modzs_to_check}\n",
    "\n",
    "    for ant in ants:\n",
    "        # parse modzs and figure out flag counts\n",
    "        modzs = {f'{pol} {rationale}': auto_metrics['modzs'][dict_name][(ant, ant, pol)] \n",
    "                 for rationale, dict_name in modzs_to_check.items() for pol in pols}\n",
    "        for pol in pols:\n",
    "            for rationale, dict_name in modzs_to_check.items():\n",
    "                binary_flags[rationale].append(auto_metrics['modzs'][dict_name][(ant, ant, pol)] > mean_round_modz_cut)\n",
    "\n",
    "        # parse out all metrics for dataframe\n",
    "        for k in modzs:\n",
    "            col_label = k + ' Modified Z-Score'\n",
    "            if col_label in all_modzs:\n",
    "                all_modzs[col_label].append(modzs[k])\n",
    "            else:\n",
    "                all_modzs[col_label] = [modzs[k]]\n",
    "                \n",
    "    mean_round_modz_cut = auto_metrics['parameters']['mean_round_modz_cut']\n",
    "else:\n",
    "    mean_round_modz_cut = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summarize ant metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-20T00:41:21.053027Z",
     "start_time": "2021-02-20T00:41:19.721Z"
    }
   },
   "outputs": [],
   "source": [
    "if use_ant_metrics:\n",
    "    a_priori_flag_frac = {ant: np.mean([ant in apxa for apxa in ant_metrics_apriori_exants.values()]) for ant in ants}\n",
    "    dead_ant_frac = {ap: {ant: np.mean([(ant, ap) in das for das in ant_metrics_dead_ants_dict.values()])\n",
    "                                 for ant in ants} for ap in antpols}\n",
    "    crossed_ant_frac = {ant: np.mean([np.any([(ant, ap) in cas for ap in antpols])\n",
    "                                      for cas in ant_metrics_crossed_ants_dict.values()]) for ant in ants}\n",
    "    ant_metrics_xants_frac_by_antpol = {antpol: np.mean([antpol in amx for amx in ant_metrics_xants_dict.values()]) for antpol in antpol_pairs}\n",
    "    ant_metrics_xants_frac_by_ant = {ant: np.mean([np.any([(ant, ap) in amx for ap in antpols])\n",
    "                                     for amx in ant_metrics_xants_dict.values()]) for ant in ants}\n",
    "    average_dead_metrics = {ap: {ant: np.nanmean([dm.get((ant, ap), np.nan) for dm in ant_metrics_dead_metrics.values()]) \n",
    "                                 for ant in ants} for ap in antpols}\n",
    "    average_crossed_metrics = {ant: np.nanmean([cm.get((ant, ap), np.nan) for ap in antpols \n",
    "                                                for cm in ant_metrics_crossed_metrics.values()]) for ant in ants}\n",
    "else:\n",
    "    dead_cut = 0.4\n",
    "    crossed_cut = 0.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summarize redcal chi^2 metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-20T00:41:21.054651Z",
     "start_time": "2021-02-20T00:41:19.723Z"
    }
   },
   "outputs": [],
   "source": [
    "if use_redcal:\n",
    "    cspa = {ant: np.nanmedian(np.hstack([cspa_med_dict[cal][ant] for cal in redcal_files])) for ant in antpol_pairs}\n",
    "    redcal_prior_flag_frac = {ant: np.mean([np.any([afd[ant, ap] and not ant in flagged_by_redcal_dict[cal] for ap in antpols])\n",
    "                                            for cal, afd in post_redcal_ant_flags_dict.items()]) for ant in ants}\n",
    "    redcal_flagged_flac = {ant: np.mean([ant in fbr for fbr in flagged_by_redcal_dict.values()]) for ant in ants}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build `DataFrame`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-20T00:41:21.056462Z",
     "start_time": "2021-02-20T00:41:19.724Z"
    }
   },
   "outputs": [],
   "source": [
    "# build dataframe\n",
    "to_show = {'Ant': ants, 'Node': [nodes[ant] for ant in ants], 'A Priori Status': [a_priori_statuses[ant] for ant in ants]}\n",
    "           #'Worst Metric': worst_metrics, 'Worst Modified Z-Score': worst_zs}\n",
    "df = pd.DataFrame(to_show)\n",
    "\n",
    "# create bar chart columns for flagging percentages:\n",
    "bar_cols = {}\n",
    "if use_auto_metrics:\n",
    "    bar_cols['Auto Metrics Flags'] = [float(ant in auto_ex_ants) for ant in ants]\n",
    "if use_ant_metrics:\n",
    "    if np.sum(list(a_priori_flag_frac.values())) > 0:  # only include this col if there are any a priori flags\n",
    "        bar_cols['A Priori Flag Fraction in Ant Metrics'] = [a_priori_flag_frac[ant] for ant in ants]\n",
    "    for ap in antpols:\n",
    "        bar_cols[f'Dead Fraction in Ant Metrics ({ap})'] = [dead_ant_frac[ap][ant] for ant in ants]\n",
    "    bar_cols['Crossed Fraction in Ant Metrics'] = [crossed_ant_frac[ant] for ant in ants]\n",
    "if use_redcal:\n",
    "    bar_cols['Flag Fraction Before Redcal'] = [redcal_prior_flag_frac[ant] for ant in ants]\n",
    "    bar_cols['Flagged By Redcal chi^2 Fraction'] = [redcal_flagged_flac[ant] for ant in ants]  \n",
    "for col in bar_cols:\n",
    "    df[col] = bar_cols[col]\n",
    "\n",
    "# add auto_metrics\n",
    "if use_auto_metrics:\n",
    "    for label, modz in all_modzs.items():\n",
    "        df[label] = modz\n",
    "z_score_cols = [col for col in df.columns if 'Modified Z-Score' in col]        \n",
    "        \n",
    "# add ant_metrics\n",
    "ant_metrics_cols = {}\n",
    "if use_ant_metrics:\n",
    "    for ap in antpols:\n",
    "        ant_metrics_cols[f'Average Dead Ant Metric ({ap})'] = [average_dead_metrics[ap][ant] for ant in ants]\n",
    "    ant_metrics_cols['Average Crossed Ant Metric'] = [average_crossed_metrics[ant] for ant in ants]\n",
    "    for col in ant_metrics_cols:\n",
    "        df[col] = ant_metrics_cols[col]   \n",
    "\n",
    "# add redcal chisq\n",
    "redcal_cols = []\n",
    "if use_redcal:\n",
    "    for ap in antpols:\n",
    "        col_title = f'Median chi^2 Per Antenna ({ap})'\n",
    "        df[col_title] = [cspa[ant, ap] for ant in ants]\n",
    "        redcal_cols.append(col_title)\n",
    "\n",
    "# sort by node number and then by antenna number within nodes\n",
    "df.sort_values(['Node', 'Ant'], ascending=True)\n",
    "\n",
    "# style dataframe\n",
    "table = df.style.hide_index()\\\n",
    "          .applymap(lambda val: f'background-color: {status_colors[val]}' if val in status_colors else '', subset=['A Priori Status']) \\\n",
    "          .background_gradient(cmap='viridis', vmax=mean_round_modz_cut * 3, vmin=0, axis=None, subset=z_score_cols) \\\n",
    "          .background_gradient(cmap='bwr_r', vmin=dead_cut-.25, vmax=dead_cut+.25, axis=0, subset=list([col for col in ant_metrics_cols if 'dead' in col.lower()])) \\\n",
    "          .background_gradient(cmap='bwr_r', vmin=crossed_cut-.25, vmax=crossed_cut+.25, axis=0, subset=list([col for col in ant_metrics_cols if 'crossed' in col.lower()])) \\\n",
    "          .background_gradient(cmap='plasma', vmax=4, vmin=1, axis=None, subset=redcal_cols) \\\n",
    "          .applymap(lambda val: 'font-weight: bold' if val < dead_cut else '', subset=list([col for col in ant_metrics_cols if 'dead' in col.lower()])) \\\n",
    "          .applymap(lambda val: 'font-weight: bold' if val < crossed_cut else '', subset=list([col for col in ant_metrics_cols if 'crossed' in col.lower()])) \\\n",
    "          .applymap(lambda val: 'font-weight: bold' if val > mean_round_modz_cut else '', subset=z_score_cols) \\\n",
    "          .applymap(lambda val: 'color: red' if val > mean_round_modz_cut else '', subset=z_score_cols) \\\n",
    "          .bar(subset=list(bar_cols.keys()), vmin=0, vmax=1) \\\n",
    "          .format({col: '{:,.4f}'.format for col in z_score_cols}) \\\n",
    "          .format({col: '{:,.4f}'.format for col in ant_metrics_cols}) \\\n",
    "          .format({col: '{:,.2%}'.format for col in bar_cols}) \\\n",
    "          .applymap(lambda val: 'font-weight: bold', subset=['Ant']) \\\n",
    "          .set_table_styles([dict(selector=\"th\",props=[('max-width', f'70pt')])]) \\"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Table 1: RTP Per-Antenna Metrics Summary Table\n",
    "\n",
    "This admittedly very busy table incorporates summary information about all antennas in the array. Its columns depend on what information is available when the notebook is run (i.e. whether `auto_metrics`, `ant_metrics`, and/or `redcal` is done). These can be divided into 5 sections:\n",
    "\n",
    "**Basic Antenna Info:** antenna number, node, and its a priori status.\n",
    "\n",
    "**Flag Fractions:** Fraction of the night that an antenna was flagged for various reasons. Note that `auto_metrics` flags antennas for the whole night, so it'll be 0% or 100%.\n",
    "\n",
    "**`auto_metrics` Details:** If `auto_metrics` is included, this section shows the modified Z-score signifying how much of an outlier each antenna and polarization is in each of four categories: bandpass shape, overall power, temporal variability, and temporal discontinuities. Bold red text indicates that this is a reason for flagging the antenna. It is reproduced from the `auto_metrics_inspect.ipynb` nightly notebook, so check that out for more details on the precise metrics.\n",
    "\n",
    "**`ant_metrics` Details:** If `ant_metrics` is included, this section shows the average correlation-based metrics for antennas over the whole night. Low \"dead ant\" metrics (nominally below 0.4) indicate antennas not correlating with the rest of the array. Negative \"crossed ant\" metrics indicate antennas that show stronger correlations in their cross-pols than their same-pols, indicating that the two polarizations are probably swapped. Bold text indicates that the average is below the threshold for flagging.\n",
    "\n",
    "**`redcal` chi^2 Details:** If `redcal` is included, this shows the median chi^2 per antenna. This would be 1 in an ideal array. Antennas are thrown out when they they are outliers in their median chi^2, usually greater than 4-sigma outliers in modified Z-score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-20T00:41:21.059504Z",
     "start_time": "2021-02-20T00:41:19.737Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "HTML(table.render())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-20T00:41:21.060840Z",
     "start_time": "2021-02-20T00:41:19.740Z"
    }
   },
   "outputs": [],
   "source": [
    "# print ex_ants for easy copy-pasting to YAML file\n",
    "proposed_ex_ants = [ant for i, ant in enumerate(ants) if np.any([col[i] > .1 for col in bar_cols.values()])]\n",
    "print('ex_ants: [' + \", \".join(str(ant) for ant in proposed_ex_ants) + ']')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-20T00:41:21.062405Z",
     "start_time": "2021-02-20T00:41:19.741Z"
    }
   },
   "outputs": [],
   "source": [
    "# write to csv\n",
    "outpath = os.path.join(nb_outdir, f'rtp_summary_table_{JD}.csv')\n",
    "print(f'Now saving Table 1 to a csv at {outpath}')\n",
    "df.to_csv(outpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-20T00:41:21.063925Z",
     "start_time": "2021-02-20T00:41:19.743Z"
    }
   },
   "outputs": [],
   "source": [
    "# Load antenna positions\n",
    "data_list = sorted(glob.glob(os.path.join(data_path, f'zen.{JD}.?????.sum.uvh5')))\n",
    "hd = io.HERAData(data_list[len(data_list) // 2])\n",
    "\n",
    "# Figure out where to draw the nodes\n",
    "node_centers = {}\n",
    "for node in sorted(set(list(nodes.values()))):\n",
    "    if np.isfinite(node):\n",
    "        this_node_ants = [ant for ant in ants if nodes[ant] == node]\n",
    "        if len(this_node_ants) == 1:\n",
    "            # put the node label just to the west of the lone antenna \n",
    "            node_centers[node] = hd.antpos[ant][node] + np.array([-14.6 / 2, 0, 0])\n",
    "        else:\n",
    "            # put the node label between the two antennas closest to the node center\n",
    "            node_centers[node] = np.mean([hd.antpos[ant] for ant in this_node_ants], axis=0)\n",
    "            closest_two_pos = sorted([hd.antpos[ant] for ant in this_node_ants], \n",
    "                                     key=lambda pos: np.linalg.norm(pos - node_centers[node]))[0:2]\n",
    "            node_centers[node] = np.mean(closest_two_pos, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-20T00:41:21.065615Z",
     "start_time": "2021-02-20T00:41:19.744Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def Plot_Array():\n",
    "    plt.figure(figsize=(16,16))\n",
    "    \n",
    "    plt.scatter(np.array([hd.antpos[ant][0] for ant in hd.data_ants]), \n",
    "                np.array([hd.antpos[ant][1] for ant in hd.data_ants]), c='w', s=0)\n",
    "\n",
    "    # connect every antenna to their node\n",
    "    for ant in ants:\n",
    "        if nodes[ant] in node_centers:\n",
    "            plt.plot([hd.antpos[ant][0], node_centers[nodes[ant]][0]], \n",
    "                     [hd.antpos[ant][1], node_centers[nodes[ant]][1]], 'k', zorder=0)\n",
    "\n",
    "    # Plot \n",
    "    for i, ant in enumerate(ants):\n",
    "        # plot large blue annuli for redcal flags\n",
    "        if use_redcal:\n",
    "            if redcal_flagged_flac[ant] > 0:\n",
    "                plt.gca().add_artist(plt.Circle(tuple(hd.antpos[ant][0:2]), radius=7, fill=True, lw=0,\n",
    "                                                color='b', alpha=redcal_flagged_flac[ant]))\n",
    "                plt.gca().add_artist(plt.Circle(tuple(hd.antpos[ant][0:2]), radius=6, fill=True, color='w'))\n",
    "        \n",
    "        # plot medium green annuli for ant_metrics flags\n",
    "        if use_ant_metrics: \n",
    "            if ant_metrics_xants_frac_by_ant[ant] > 0:\n",
    "                plt.gca().add_artist(plt.Circle(tuple(hd.antpos[ant][0:2]), radius=6, fill=True, lw=0,\n",
    "                                                color='lime', alpha=ant_metrics_xants_frac_by_ant[ant]))\n",
    "                plt.gca().add_artist(plt.Circle(tuple(hd.antpos[ant][0:2]), radius=5, fill=True, color='w'))\n",
    "        \n",
    "        # plot small red annuli for auto_metrics\n",
    "        if use_auto_metrics:\n",
    "            if ant in auto_ex_ants:\n",
    "                plt.gca().add_artist(plt.Circle(tuple(hd.antpos[ant][0:2]), radius=5, fill=True, lw=0, color='r')) \n",
    "        \n",
    "        # plot white circles with black outlines for antennas\n",
    "        plt.gca().add_artist(plt.Circle(tuple(hd.antpos[ant][0:2]), radius=4, fill=True, color='w', ec='k'))\n",
    "\n",
    "        # label antennas, using apriori statuses if available\n",
    "        try:\n",
    "            bgc = matplotlib.colors.to_rgb(status_colors[a_priori_statuses[ant]])\n",
    "            c = 'black' if (bgc[0]*0.299 + bgc[1]*0.587 + bgc[2]*0.114) > 186 / 256 else 'white'\n",
    "        except:\n",
    "            c = 'k'\n",
    "            bgc='white'\n",
    "        plt.text(hd.antpos[ant][0], hd.antpos[ant][1], str(ant), va='center', ha='center', color=c, backgroundcolor=bgc)\n",
    "\n",
    "    # label nodes\n",
    "    for node in sorted(set(list(nodes.values()))):\n",
    "        plt.text(node_centers[node][0], node_centers[node][1], str(node), va='center', ha='center', bbox={'color': 'w', 'ec': 'k'})\n",
    "    \n",
    "    # build legend \n",
    "    legend_objs = []\n",
    "    legend_labels = []\n",
    "    \n",
    "    # use circles for annuli \n",
    "    if use_redcal:\n",
    "        legend_objs.append(matplotlib.lines.Line2D([0], [0], marker='o', color='w', markerfacecolor='r', markersize=15))\n",
    "        legend_labels.append('Flagged by Auto Metrics')\n",
    "    if use_ant_metrics: \n",
    "        legend_objs.append(matplotlib.lines.Line2D([0], [0], marker='o', color='w', markerfacecolor='lime', markersize=15))\n",
    "        legend_labels.append('Flagged by Ant Metrics\\n(alpha indicates fraction of time)')\n",
    "    if use_auto_metrics:\n",
    "        legend_objs.append(matplotlib.lines.Line2D([0], [0], marker='o', color='w', markerfacecolor='b', markersize=15))\n",
    "        legend_labels.append('Flagged by Redcal\\n(alpha indicates fraction of time)')\n",
    "\n",
    "    # use rectangular patches for a priori statuses that appear in the array\n",
    "    for aps in sorted(list(set(list(a_priori_statuses.values())))):\n",
    "        if aps != 'Not Found':\n",
    "            legend_objs.append(plt.Circle((0, 0), radius=7, fill=True, color=status_colors[aps]))\n",
    "            legend_labels.append(f'A Priori Status:\\n{aps} ({list(a_priori_statuses.values()).count(aps)} Antennas)')\n",
    "\n",
    "    # label nodes as a white box with black outline\n",
    "    if len(node_centers) > 0:\n",
    "        legend_objs.append(matplotlib.patches.Patch(facecolor='w', edgecolor='k'))\n",
    "        legend_labels.append('Node Number')\n",
    "\n",
    "    plt.legend(legend_objs, legend_labels, fontsize='large')\n",
    "    \n",
    "    # set axis equal and label everything\n",
    "    plt.axis('equal')\n",
    "    plt.tight_layout()\n",
    "    plt.title(f'Summary of Antenna Statuses and Metrics on {JD}', size=20)    \n",
    "    plt.xlabel(\"Antenna East-West Position (meters)\", size=12)\n",
    "    plt.ylabel(\"Antenna North-South Position (meters)\", size=12)\n",
    "    plt.xticks(fontsize=12)\n",
    "    plt.yticks(fontsize=12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Figure 1: Array Plot of Flags and A Priori Statuses\n",
    "\n",
    "This plot shows all antennas, which nodes they are connected to, and their a priori statuses (as the highlight text of their antenna numbers). It may also show (depending on what is finished running):\n",
    "* Whether they were flagged by `auto_metrics` (red circle) for bandpass shape, overall power, temporal variability, or temporal discontinuities. This is done in a binary fashion for the whole night.\n",
    "* Whether they were flagged by `ant_metrics` (green circle) as either dead (on either polarization) or crossed, with the transparency indicating the fraction of the night (i.e. number of files) that were flagged.\n",
    "* Whether they were flagged by `redcal` (blue circle) for high s either dead (on either polarization) or crossed, with the transparency indicating the fraction of the night (i.e. number of files) that were flagged. \n",
    "\n",
    "*Note that the last fraction does not include antennas that were flagged before going into redcal due to their a priori status, for example.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-20T00:41:21.067025Z",
     "start_time": "2021-02-20T00:41:19.746Z"
    }
   },
   "outputs": [],
   "source": [
    "Plot_Array()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-20T00:41:21.068387Z",
     "start_time": "2021-02-20T00:41:19.747Z"
    }
   },
   "outputs": [],
   "source": [
    "from hera_qm import version\n",
    "print(version.construct_version_info())\n",
    "print(redcal.version.history_string())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
