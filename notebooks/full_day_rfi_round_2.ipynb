{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c468fb39",
   "metadata": {},
   "source": [
    "# Second Round of Full Day RFI Flagging\n",
    "\n",
    "**by Josh Dillon**, last updated October 13, 2024\n",
    "\n",
    "This notebook is synthesizes information from individual [delay_filtered_average_zscore](https://github.com/HERA-Team/hera_notebook_templates/blob/master/notebooks/delay_filtered_average_zscore.ipynb) notebooks to find low-level RFI and flag it. That notebook takes `smooth_cal`ibrated data, redundantly averages it, performs a high-pass delay filter, and then incoherently averages across baselines, creating a per-polarization z-score. This notebook then takes that whole night of z-scores and finds a new set of flags to both add to the `smooth_cal` files, which are updated in place, and to write down as new `UVFlag` waterfall-type `.h5` files.\n",
    "\n",
    "Here's a set of links to skip to particular figures and tables:\n",
    "\n",
    "\n",
    "# [• Figure 1: Waterfall of Maximum z-Score of Either Polarization Before Round 2 Flagging](#Figure-1:-Waterfall-of-Maximum-z-Score-of-Either-Polarization-Before-Round-2-Flagging)\n",
    "# [• Figure 2: Histogram of z-scores](#Figure-2:-Histogram-of-z-scores)\n",
    "# [• Figure 3: Waterfall of Maximum z-Score of Either Polarization After Round 2 Flagging](#Figure-3:-Waterfall-of-Maximum-z-Score-of-Either-Polarization-After-Round-2-Flagging)\n",
    "# [• Figure 4: Spectra of Time-Averaged z-Scores](#Figure-4:-Spectra-of-Time-Averaged-z-Scores)\n",
    "# [• Figure 5: Summary of Flags Before and After Round 2 Flagging](#Figure-5:-Summary-of-Flags-Before-and-After-Round-2-Flagging)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c085a84e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "tstart = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a63080ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['HDF5_USE_FILE_LOCKING'] = 'FALSE'\n",
    "import h5py\n",
    "import hdf5plugin  # REQUIRED to have the compression plugins available\n",
    "import numpy as np\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import copy\n",
    "import warnings\n",
    "from pyuvdata import UVFlag, UVCal\n",
    "from hera_cal import utils\n",
    "from hera_qm import xrfi\n",
    "from hera_qm.time_series_metrics import true_stretches\n",
    "from hera_filters import dspec\n",
    "\n",
    "from IPython.display import display, HTML\n",
    "%matplotlib inline\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))\n",
    "_ = np.seterr(all='ignore')  # get rid of red warnings\n",
    "%config InlineBackend.figure_format = 'retina'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f921c49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get input data file names\n",
    "SUM_FILE = os.environ.get(\"SUM_FILE\", None)\n",
    "# SUM_FILE = '/lustre/aoc/projects/hera/h6c-analysis/IDR2/2459861/zen.2459861.25297.sum.uvh5'\n",
    "SUM_SUFFIX = os.environ.get(\"SUM_SUFFIX\", 'sum.uvh5')\n",
    "\n",
    "# get input and output suffixes\n",
    "SMOOTH_CAL_SUFFIX = os.environ.get(\"SMOOTH_CAL_SUFFIX\", 'sum.smooth.calfits')\n",
    "ZSCORE_SUFFIX =  os.environ.get(\"ZSCORE_SUFFIX\", 'sum.red_avg_zscore.h5')\n",
    "FLAG_WATERFALL2_SUFFIX = os.environ.get(\"FLAG_WATERFALL2_SUFFIX\", 'sum.flag_waterfall_round_2.h5')\n",
    "OUT_YAML_SUFFIX = os.environ.get(\"OUT_YAML_SUFFIX\", '_aposteriori_flags.yaml')\n",
    "OUT_YAML_DIR = os.environ.get(\"OUT_YAML_DIR\", None)\n",
    "\n",
    "# build globs\n",
    "sum_glob = '.'.join(SUM_FILE.split('.')[:-3]) + '.*.' + SUM_SUFFIX\n",
    "cal_files_glob = sum_glob.replace(SUM_SUFFIX, SMOOTH_CAL_SUFFIX)\n",
    "zscore_glob = sum_glob.replace(SUM_SUFFIX, ZSCORE_SUFFIX)\n",
    "\n",
    "# build out yaml file\n",
    "if OUT_YAML_DIR is None:\n",
    "    OUT_YAML_DIR = os.path.dirname(SUM_FILE)\n",
    "out_yaml_file = os.path.join(OUT_YAML_DIR, SUM_FILE.split('.')[-4] + OUT_YAML_SUFFIX)    \n",
    "\n",
    "# get flagging parameters\n",
    "Z_THRESH = float(os.environ.get(\"Z_THRESH\", 4))\n",
    "WS_Z_THRESH = float(os.environ.get(\"WS_Z_THRESH\", 2))\n",
    "AVG_Z_THRESH = float(os.environ.get(\"AVG_Z_THRESH\", 1))\n",
    "MAX_FREQ_FLAG_FRAC = float(os.environ.get(\"MAX_FREQ_FLAG_FRAC\", .25))\n",
    "MAX_TIME_FLAG_FRAC = float(os.environ.get(\"MAX_TIME_FLAG_FRAC\", .1))\n",
    "AVG_SPECTRUM_FILTER_DELAY = float(os.environ.get(\"AVG_SPECTRUM_FILTER_DELAY\", 250)) # in ns\n",
    "EIGENVAL_CUTOFF = float(os.environ.get(\"EIGENVAL_CUTOFF\", 1e-12))\n",
    "TIME_AVG_DELAY_FILT_SNR_THRESH = float(os.environ.get(\"TIME_AVG_DELAY_FILT_SNR_THRESH\", 4.0))\n",
    "TIME_AVG_DELAY_FILT_SNR_DYNAMIC_RANGE = float(os.environ.get(\"TIME_AVG_DELAY_FILT_SNR_DYNAMIC_RANGE\", 1.5))\n",
    "\n",
    "for setting in ['Z_THRESH', 'WS_Z_THRESH', 'AVG_Z_THRESH', 'MAX_FREQ_FLAG_FRAC', 'MAX_TIME_FLAG_FRAC',\n",
    "               'EIGENVAL_CUTOFF', 'TIME_AVG_DELAY_FILT_SNR_THRESH', 'TIME_AVG_DELAY_FILT_SNR_DYNAMIC_RANGE']:\n",
    "    print(f'{setting} = {eval(setting)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab3d3a00",
   "metadata": {},
   "source": [
    "# Load z-scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c192b28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load z-scores\n",
    "zscore_files = sorted(glob.glob(zscore_glob))\n",
    "print(f'Found {len(zscore_files)} *.{ZSCORE_SUFFIX} files starting with {zscore_files[0]}.')\n",
    "uvf = UVFlag(zscore_files, use_future_array_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e2d5638",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get calibration solution files\n",
    "cal_files = sorted(glob.glob(cal_files_glob))\n",
    "print(f'Found {len(cal_files)} *.{SMOOTH_CAL_SUFFIX} files starting with {cal_files[0]}.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9f7db5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(zscore_files) == len(cal_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c632acdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract z-scores and correct by a single number per polarization to account for biases created by filtering\n",
    "zscore = {pol: uvf.metric_array[:, :, np.argwhere(uvf.polarization_array == utils.polstr2num(pol, x_orientation=uvf.x_orientation))[0][0]] for pol in ['ee', 'nn']}\n",
    "zscore = {pol: zscore[pol] - np.nanmedian(zscore[pol]) for pol in zscore}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03a6c012",
   "metadata": {},
   "outputs": [],
   "source": [
    "freqs = uvf.freq_array\n",
    "times = uvf.time_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cb30c35",
   "metadata": {},
   "outputs": [],
   "source": [
    "extent = [freqs[0] / 1e6, freqs[-1] / 1e6, times[-1] - int(times[0]), times[0] - int(times[0])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71232731",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_max_z_score(zscore, flags=None, vmin=-5, vmax=5):\n",
    "    if flags is None:\n",
    "        flags = np.any(~np.isfinite(list(zscore.values())), axis=0)\n",
    "    plt.figure(figsize=(14,10), dpi=100)\n",
    "    plt.imshow(np.where(flags, np.nan, np.nanmax([zscore['ee'], zscore['nn']], axis=0)), aspect='auto', \n",
    "               cmap='coolwarm', interpolation='none', vmin=vmin, vmax=vmax, extent=extent)\n",
    "    plt.colorbar(location='top', label='Max z-score of either polarization', extend='both', aspect=40, pad=.02)\n",
    "    plt.xlabel('Frequency (MHz)')\n",
    "    plt.ylabel(f'JD - {int(times[0])}')\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "546ef859",
   "metadata": {},
   "source": [
    "# *Figure 1: Waterfall of Maximum z-Score of Either Polarization Before Round 2 Flagging*\n",
    "\n",
    "Shows the worse of the two results from [delay_filtered_average_zscore](https://github.com/HERA-Team/hera_notebook_templates/blob/master/notebooks/delay_filtered_average_zscore.ipynb) from either polarization. Dips near flagged channels are expected, due to overfitting of noise. Positive-going excursions are problematic and likely evidence of RFI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf8ae866",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_max_z_score(zscore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9148d339",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_histogram():\n",
    "    plt.figure(figsize=(14,4), dpi=100)\n",
    "    bins = np.arange(-50, 100, .1)\n",
    "    hist_ee = plt.hist(np.ravel(zscore['ee']), bins=bins, density=True, label='ee-polarized z-scores', alpha=.5)\n",
    "    hist_nn = plt.hist(np.ravel(zscore['nn']), bins=bins, density=True, label='nn-polarized z-scores', alpha=.5)\n",
    "    plt.plot(bins, (2*np.pi)**-.5 * np.exp(-bins**2 / 2), 'k:', label='Gaussian approximate\\nnoise-only distribution')\n",
    "    plt.axvline(WS_Z_THRESH, c='r', ls='--', label='Watershed z-score')\n",
    "    plt.axvline(Z_THRESH, c='r', ls='-', label='Threshold z-score')\n",
    "    plt.yscale('log')\n",
    "    all_densities = np.concatenate([hist_ee[0][hist_ee[0] > 0], hist_nn[0][hist_nn[0] > 0]]) \n",
    "    plt.ylim(np.min(all_densities) / 2, np.max(all_densities) * 2)\n",
    "    plt.xlim([-50, 100])\n",
    "    plt.legend()\n",
    "    plt.xlabel('z-score')\n",
    "    plt.ylabel('Density')\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "251f8ae0",
   "metadata": {},
   "source": [
    "# *Figure 2: Histogram of z-scores*\n",
    "\n",
    "Shows a comparison of the histogram of z-scores in this file (one per polarization) to a Gaussian approximation of what one might expect from thermal noise. Without filtering, the actual distribution is a weighted sum of Rayleigh distributions. Filtering further complicates this. To make the z-scores more reliable, a single per-polarization median is subtracted from each waterfall, which allows us to flag low-level outliers with more confidence. Any points beyond the solid red line are flagged. Any points neighboring a flag beyond the dashed red line are also flagged. Finally, flagging is performed for low-level outliers in whole times or channels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0c5aa54",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_histogram()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ac7bfe1",
   "metadata": {},
   "source": [
    "## Perform flagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6f0d686",
   "metadata": {},
   "outputs": [],
   "source": [
    "def iteratively_flag_on_averaged_zscore(flags, zscore, avg_func=np.nanmean, avg_z_thresh=AVG_Z_THRESH, verbose=True):\n",
    "    '''Flag whole integrations or channels based on average z-score. This is done\n",
    "    iteratively to prevent bad times affecting channel averages or vice versa.'''\n",
    "    flagged_chan_count = 0\n",
    "    flagged_int_count = 0\n",
    "    while True:\n",
    "        zspec = avg_func(np.where(flags, np.nan, zscore), axis=0)\n",
    "        ztseries = avg_func(np.where(flags, np.nan, zscore), axis=1)\n",
    "\n",
    "        if (np.nanmax(zspec) < avg_z_thresh) and (np.nanmax(ztseries) < avg_z_thresh):\n",
    "            break\n",
    "\n",
    "        if np.nanmax(zspec) >= np.nanmax(ztseries):\n",
    "            flagged_chan_count += np.sum((zspec >= np.nanmax(ztseries)) & (zspec >= avg_z_thresh))\n",
    "            flags[:, (zspec >= np.nanmax(ztseries)) & (zspec >= avg_z_thresh)] = True\n",
    "        else:\n",
    "            flagged_int_count += np.sum((ztseries >= np.nanmax(zspec)) & (ztseries >= avg_z_thresh))\n",
    "            flags[(ztseries >= np.nanmax(zspec)) & (ztseries >= avg_z_thresh), :] = True\n",
    "\n",
    "    if verbose:\n",
    "        print(f'\\tFlagging an additional {flagged_int_count} integrations and {flagged_chan_count} channels.')\n",
    "\n",
    "def impose_max_chan_flag_frac(flags, max_flag_frac=MAX_FREQ_FLAG_FRAC, verbose=True):\n",
    "    '''Flag channels already flagged more than max_flag_frac (excluding completely flagged times).'''\n",
    "    unflagged_times = ~np.all(flags, axis=1)\n",
    "    frequently_flagged_chans =  np.mean(flags[unflagged_times, :], axis=0) >= max_flag_frac\n",
    "    if verbose:\n",
    "        print(f'\\tFlagging {np.sum(frequently_flagged_chans) - np.sum(np.all(flags, axis=0))} channels previously flagged {max_flag_frac:.2%} or more.')        \n",
    "    flags[:, frequently_flagged_chans] = True \n",
    "        \n",
    "def impose_max_time_flag_frac(flags, max_flag_frac=MAX_TIME_FLAG_FRAC, verbose=True):\n",
    "    '''Flag times already flagged more than max_flag_frac (excluding completely flagged channels).'''\n",
    "    unflagged_chans = ~np.all(flags, axis=0)\n",
    "    frequently_flagged_times =  np.mean(flags[:, unflagged_chans], axis=1) >= max_flag_frac\n",
    "    if verbose:\n",
    "        print(f'\\tFlagging {np.sum(frequently_flagged_times) - np.sum(np.all(flags, axis=1))} times previously flagged {max_flag_frac:.2%} or more.')\n",
    "    flags[frequently_flagged_times, :] = True\n",
    "\n",
    "def time_avg_zscore_dly_filt_SNRs(flags, filter_delay=AVG_SPECTRUM_FILTER_DELAY, eigenval_cutoff=EIGENVAL_CUTOFF):\n",
    "    \"\"\"Produces SNRs after time-averaging z-scores and delay filtering, accounting for flagging's effect on the filter.\"\"\"\n",
    "    # figure out high and low band based on FM gap at 100 MHz\n",
    "    flagged_stretches = true_stretches(np.all(flags, axis=0))\n",
    "    FM_gap = [fs for fs in flagged_stretches if fs.start <= np.argmin(np.abs(freqs - 100e6)) < fs.stop][0]\n",
    "    low_band = slice((0 if flagged_stretches[0].start != 0 else flagged_stretches[0].stop), FM_gap.start)\n",
    "    high_band = slice(FM_gap.stop, (len(freqs) if flagged_stretches[-1].stop != len(freqs) else flagged_stretches[-1].start))\n",
    "    \n",
    "    filt_SNR = {}\n",
    "    for pol in zscore:\n",
    "        # calculate timeavg_SNR and filter\n",
    "        noise_prediction = 1.0 / np.sum(~flags, axis=0)**.5\n",
    "        timeavg_SNR = np.nanmean(np.where(flags, np.nan, zscore[pol] / noise_prediction), axis=0) \n",
    "        wgts = np.where(np.isfinite(timeavg_SNR), 1, 0)\n",
    "        model = np.zeros_like(timeavg_SNR)\n",
    "        for band in [low_band, high_band]:\n",
    "            model[band], _, _ = dspec.fourier_filter(freqs[band], np.where(np.isfinite(timeavg_SNR[band]), timeavg_SNR[band], 0),\n",
    "                                                     wgts[band], [0], [AVG_SPECTRUM_FILTER_DELAY / 1e9], mode=\"dpss_solve\", \n",
    "                                                     eigenval_cutoff=[EIGENVAL_CUTOFF], suppression_factors=[EIGENVAL_CUTOFF])\n",
    "        filt_SNR[pol] = timeavg_SNR - model\n",
    "\n",
    "        # correct for impact of filter\n",
    "        correction_factors = np.ones_like(wgts) * np.nan\n",
    "        for band in [low_band, high_band]:\n",
    "            X = dspec.dpss_operator(freqs[band], [0], filter_half_widths=[AVG_SPECTRUM_FILTER_DELAY / 1e9], eigenval_cutoff=[EIGENVAL_CUTOFF])[0]\n",
    "            W = wgts[band]\n",
    "            leverage = np.diag(X @ np.linalg.pinv(np.dot(X.T * W, X)) @ (X.T * W))\n",
    "            correction_factors[band] = np.where(leverage > 0, (1 - leverage)**.5, np.nan) # because the underlying data should be gaussian\n",
    "        filt_SNR[pol] /= correction_factors\n",
    "    \n",
    "    return filt_SNR\n",
    "\n",
    "def iteratively_flag_on_delay_filtered_time_avg_zscore(flags, thresh=TIME_AVG_DELAY_FILT_SNR_THRESH, dynamic_range=TIME_AVG_DELAY_FILT_SNR_DYNAMIC_RANGE,\n",
    "                                                       filter_delay=AVG_SPECTRUM_FILTER_DELAY, eigenval_cutoff=EIGENVAL_CUTOFF):\n",
    "    \"\"\"Flag whole channels based on their outlierness after delay-filterd time-averaged zscores.\n",
    "    This is done iteratively since the delay filter can be unduly influenced by large outliers.\"\"\"\n",
    "    filt_SNR = time_avg_zscore_dly_filt_SNRs(flags, filter_delay=AVG_SPECTRUM_FILTER_DELAY, eigenval_cutoff=EIGENVAL_CUTOFF)\n",
    "    while True:\n",
    "        largest_SNR = np.nanmax(list(filt_SNR.values()))\n",
    "        if largest_SNR < thresh:\n",
    "            break\n",
    "        # \n",
    "        cut = np.max([thresh, largest_SNR / dynamic_range])\n",
    "        for pol in filt_SNR:\n",
    "            flags[:, filt_SNR[pol] > cut] = True\n",
    "        filt_SNR = time_avg_zscore_dly_filt_SNRs(flags, filter_delay=AVG_SPECTRUM_FILTER_DELAY, eigenval_cutoff=EIGENVAL_CUTOFF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd2d1564",
   "metadata": {},
   "outputs": [],
   "source": [
    "flags = np.any(~np.isfinite(list(zscore.values())), axis=0)\n",
    "print(f'{np.mean(flags):.3%} of waterfall flagged to start.')\n",
    "\n",
    "# flag whole integrations or channels using outliers in median\n",
    "while True:\n",
    "    nflags = np.sum(flags)\n",
    "    for pol in ['ee', 'nn']:    \n",
    "        iteratively_flag_on_averaged_zscore(flags, zscore[pol], avg_func=np.nanmedian, avg_z_thresh=AVG_Z_THRESH, verbose=True)\n",
    "        impose_max_chan_flag_frac(flags, max_flag_frac=MAX_FREQ_FLAG_FRAC, verbose=True)\n",
    "        impose_max_time_flag_frac(flags, max_flag_frac=MAX_TIME_FLAG_FRAC, verbose=True)\n",
    "    if np.sum(flags) == nflags:\n",
    "        break  \n",
    "print(f'{np.mean(flags):.3%} of waterfall flagged after flagging whole times and channels with median z > {AVG_Z_THRESH}.')\n",
    "\n",
    "# flag largest outliers\n",
    "for pol in ['ee', 'nn']:\n",
    "    flags |= (zscore[pol] > Z_THRESH) \n",
    "print(f'{np.mean(flags):.3%} of waterfall flagged after flagging z > {Z_THRESH} outliers.')\n",
    "    \n",
    "# watershed flagging\n",
    "while True:\n",
    "    nflags = np.sum(flags)\n",
    "    for pol in ['ee', 'nn']:\n",
    "        flags |= xrfi._ws_flag_waterfall(zscore[pol], flags, WS_Z_THRESH)\n",
    "    if np.sum(flags) == nflags:\n",
    "        break\n",
    "print(f'{np.mean(flags):.3%} of waterfall flagged after watershed flagging on z > {WS_Z_THRESH} neighbors of prior flags.')\n",
    "        \n",
    "# flag whole integrations or channels using outliers in mean\n",
    "while True:\n",
    "    nflags = np.sum(flags)\n",
    "    for pol in ['ee', 'nn']:    \n",
    "        iteratively_flag_on_averaged_zscore(flags, zscore[pol], avg_func=np.nanmean, avg_z_thresh=AVG_Z_THRESH, verbose=True)\n",
    "        impose_max_chan_flag_frac(flags, max_flag_frac=MAX_FREQ_FLAG_FRAC, verbose=True)\n",
    "        impose_max_time_flag_frac(flags, max_flag_frac=MAX_TIME_FLAG_FRAC, verbose=True)\n",
    "    if np.sum(flags) == nflags:\n",
    "        break  \n",
    "print(f'{np.mean(flags):.3%} of waterfall flagged after flagging whole times and channels with average z > {AVG_Z_THRESH}.')\n",
    "\n",
    "# flag channels based on delay filter\n",
    "iteratively_flag_on_delay_filtered_time_avg_zscore(flags, thresh=TIME_AVG_DELAY_FILT_SNR_THRESH, dynamic_range=TIME_AVG_DELAY_FILT_SNR_DYNAMIC_RANGE,\n",
    "                                                   filter_delay=AVG_SPECTRUM_FILTER_DELAY, eigenval_cutoff=EIGENVAL_CUTOFF)\n",
    "print(f'{np.mean(flags):.3%} of flagging channels that are {TIME_AVG_DELAY_FILT_SNR_THRESH}σ outliers after delay filtering the time average.')\n",
    "\n",
    "# watershed flagging again\n",
    "while True:\n",
    "    nflags = np.sum(flags)\n",
    "    for pol in ['ee', 'nn']:\n",
    "        flags |= xrfi._ws_flag_waterfall(zscore[pol], flags, WS_Z_THRESH)\n",
    "    if np.sum(flags) == nflags:\n",
    "        break\n",
    "print(f'{np.mean(flags):.3%} of waterfall flagged after another round of watershed flagging on z > {WS_Z_THRESH} neighbors of prior flags.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c612c997",
   "metadata": {},
   "source": [
    "## Show results of flagging"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08d9e798",
   "metadata": {},
   "source": [
    "# *Figure 3: Waterfall of Maximum z-Score of Either Polarization After Round 2 Flagging*\n",
    "\n",
    "The same as Figure 1, but after the flagging performed in this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b71cddcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_max_z_score(zscore, flags=flags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fffcec6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def zscore_spectra(ylim=[-3, 3], flags=flags):\n",
    "    fig, axes = plt.subplots(2, 1, figsize=(14,6), dpi=100, sharex=True, sharey=True, gridspec_kw={'hspace': 0})\n",
    "    for ax, pol in zip(axes, ['ee', 'nn']):\n",
    "\n",
    "        ax.plot(freqs / 1e6, np.nanmean(zscore[pol], axis=0),'r', label=f'{pol}-Polarization Before Round 2 Flagging', lw=.5)\n",
    "        ax.plot(freqs / 1e6, np.nanmean(np.where(flags, np.nan, zscore[pol]), axis=0), label=f'{pol}-Polarization After Round 2 Flagging')\n",
    "        ax.legend(loc='lower right')\n",
    "        ax.set_ylabel('Time-Averged Z-Score\\n(Excluding Flags)')\n",
    "        ax.set_ylim(ylim)\n",
    "    axes[1].set_xlabel('Frequency (MHz)')\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ccd66b2",
   "metadata": {},
   "source": [
    "# *Figure 4: Spectra of Time-Averaged z-Scores*\n",
    "\n",
    "The average along the time axis of Figures 1 and 3 (though now separated per-polarization). This plot is useful for showing channels with repeated low-level RFI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3589d99",
   "metadata": {},
   "outputs": [],
   "source": [
    "zscore_spectra()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f31ec57",
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize_flagging(flags=flags):\n",
    "    plt.figure(figsize=(14,10), dpi=100)\n",
    "    cmap = matplotlib.colors.ListedColormap(((0, 0, 0),) + matplotlib.cm.get_cmap(\"Set2\").colors[0:2])\n",
    "    plt.imshow(np.where(np.any(~np.isfinite(list(zscore.values())), axis=0), 1, np.where(flags, 2, 0)), \n",
    "               aspect='auto', cmap=cmap, interpolation='none', extent=extent)\n",
    "    plt.clim([-.5, 2.5])\n",
    "    cbar = plt.colorbar(location='top', aspect=40, pad=.02)\n",
    "    cbar.set_ticks([0, 1, 2])\n",
    "    cbar.set_ticklabels(['Unflagged', 'Previously Flagged', 'Flagged Here Using Delayed Filtered z-Scores'])\n",
    "    plt.xlabel('Frequency (MHz)')\n",
    "    plt.ylabel(f'JD - {int(times[0])}')\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e50ed13c",
   "metadata": {},
   "source": [
    "# *Figure 5: Summary of Flags Before and After Round 2 Flagging*\n",
    "\n",
    "This plot shows which times and frequencies were flagged before and after this notebook. It is directly comparable to Figure 5 of the first round [full_day_rfi](https://github.com/HERA-Team/hera_notebook_templates/blob/master/notebooks/full_day_rfi.ipynb) notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e08492e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "summarize_flagging()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85224d0f",
   "metadata": {},
   "source": [
    "## Save results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14884b7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "add_to_history = 'by full_day_rfi_round_2 notebook with the following environment:\\n' + '=' * 65 + '\\n' + os.popen('conda env export').read() + '=' * 65"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4729449e",
   "metadata": {},
   "outputs": [],
   "source": [
    "tind = 0\n",
    "always_flagged_ants = set()\n",
    "ever_unflagged_ants = set()\n",
    "for cal_file in cal_files:\n",
    "    with warnings.catch_warnings():\n",
    "        warnings.simplefilter(\"ignore\")    \n",
    "        \n",
    "        # update cal_file\n",
    "        uvc = UVCal()\n",
    "        uvc.read(cal_file, use_future_array_shapes=True)\n",
    "        uvc.flag_array |= (flags[tind:tind + len(uvc.time_array), :].T)[None, :, :, None]\n",
    "        uvc.history += 'Modified ' + add_to_history\n",
    "        uvc.write_calfits(cal_file, clobber=True)\n",
    "        \n",
    "        # keep track of flagged antennas\n",
    "        for antnum in uvc.ant_array:\n",
    "            for antpol in ['Jee', 'Jnn']:\n",
    "                if np.all(uvc.get_flags(antnum, antpol)):\n",
    "                    if (antnum, antpol) not in ever_unflagged_ants:\n",
    "                        always_flagged_ants.add((antnum, antpol))\n",
    "                else:\n",
    "                    ever_unflagged_ants.add((antnum, antpol))\n",
    "                    always_flagged_ants.discard((antnum, antpol))\n",
    "                \n",
    "\n",
    "        # Create new flag object\n",
    "        uvf_out = UVFlag(uvc, waterfall=True, mode='flag')\n",
    "        uvf_out.flag_array |= flags[tind:tind + len(uvc.time_array), :, None]\n",
    "        uvf_out.history += 'Produced ' + add_to_history\n",
    "        uvf_out.write(cal_file.replace(SMOOTH_CAL_SUFFIX, FLAG_WATERFALL2_SUFFIX), clobber=True)\n",
    "        \n",
    "        # increment time index\n",
    "        tind += len(uvc.time_array)\n",
    "\n",
    "print(f'Saved {len(cal_files)} *.{FLAG_WATERFALL2_SUFFIX} files starting with {cal_files[0].replace(SMOOTH_CAL_SUFFIX, FLAG_WATERFALL2_SUFFIX)}.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1b51d11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# write summary of entirely flagged times/freqs/ants to yaml\n",
    "all_flagged_times = np.all(flags, axis=1)\n",
    "all_flagged_freqs = np.all(flags, axis=0)\n",
    "all_flagged_ants = sorted(always_flagged_ants)\n",
    "\n",
    "dt = np.median(np.diff(times))\n",
    "out_yml_str = 'JD_flags: ' + str([[times[flag_stretch][0] - dt / 2, times[flag_stretch][-1] + dt / 2] \n",
    "                                  for flag_stretch in true_stretches(all_flagged_times)])\n",
    "df = np.median(np.diff(freqs))\n",
    "out_yml_str += '\\n\\nfreq_flags: ' + str([[freqs[flag_stretch][0] - df / 2, freqs[flag_stretch][-1] + df / 2] \n",
    "                                         for flag_stretch in true_stretches(all_flagged_freqs)])\n",
    "out_yml_str += '\\n\\nex_ants: ' + str(all_flagged_ants).replace(\"'\", \"\").replace('(', '[').replace(')', ']')\n",
    "\n",
    "print(f'Writing the following to {out_yaml_file}\\n' + '-' * (25 + len(out_yaml_file)))\n",
    "print(out_yml_str)\n",
    "with open(out_yaml_file, 'w') as outfile:\n",
    "    outfile.writelines(out_yml_str)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0e1ea9f",
   "metadata": {},
   "source": [
    "## Metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b67d967",
   "metadata": {},
   "outputs": [],
   "source": [
    "for repo in ['hera_cal', 'hera_qm', 'hera_filters', 'hera_notebook_templates', 'pyuvdata']:\n",
    "    exec(f'from {repo} import __version__')\n",
    "    print(f'{repo}: {__version__}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f691a79",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Finished execution in {(time.time() - tstart) / 60:.2f} minutes.')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "165px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
